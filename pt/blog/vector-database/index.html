<!doctype html>
<html lang="pt-BR" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Como armazenar conhecimento com bancos de dados vetoriais? | Brain¬†Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" property="og:url" content="https://tchez.dev/pt/blog/vector-database/"><meta data-rh="true" property="og:locale" content="pt_BR"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="pt"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="pt"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:creator" content="@_tchez"><meta data-rh="true" name="twitter:title" content="Brain Blog ‚Äì AI, Notes &amp; Projects"><meta data-rh="true" name="twitter:description" content="Articles, structured notes and project logs by Marco Ant√¥nio."><meta data-rh="true" property="og:title" content="Como armazenar conhecimento com bancos de dados vetoriais? | Brain¬†Blog"><meta data-rh="true" name="description" content="Em um mundo inundado de dados n√£o estruturados, como podemos armazenar n√£o apenas informa√ß√µes, mas conhecimento? Este artigo mergulha nos bancos de dados vetoriais - uma abordagem revolucion√°ria que permite busca baseada em similaridade e compreens√£o sem√¢ntica. Aprenda como vetores e embeddings reformulam o armazenamento de dados, potencializam aplica√ß√µes avan√ßadas de IA e marcam uma mudan√ßa dos bancos de dados tradicionais para sistemas orientados ao conhecimento."><meta data-rh="true" property="og:description" content="Em um mundo inundado de dados n√£o estruturados, como podemos armazenar n√£o apenas informa√ß√µes, mas conhecimento? Este artigo mergulha nos bancos de dados vetoriais - uma abordagem revolucion√°ria que permite busca baseada em similaridade e compreens√£o sem√¢ntica. Aprenda como vetores e embeddings reformulam o armazenamento de dados, potencializam aplica√ß√µes avan√ßadas de IA e marcam uma mudan√ßa dos bancos de dados tradicionais para sistemas orientados ao conhecimento."><meta data-rh="true" name="keywords" content="banco de dados vetorial,armazenamento de conhecimento,busca sem√¢ntica,embeddings,intelig√™ncia artificial,PNL,recupera√ß√£o aumentada por gera√ß√£o"><meta data-rh="true" property="og:image" content="https://tchez.dev/pt/img/vector-database-og-pt.png"><meta data-rh="true" name="twitter:image" content="https://tchez.dev/pt/img/vector-database-og-pt.png"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-06-12T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/tchez"><meta data-rh="true" property="article:tag" content="rag,ai,programming,article"><link data-rh="true" rel="icon" href="/pt/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://tchez.dev/pt/blog/vector-database/"><link data-rh="true" rel="alternate" href="https://tchez.dev/blog/vector-database/" hreflang="en"><link data-rh="true" rel="alternate" href="https://tchez.dev/pt/blog/vector-database/" hreflang="pt-BR"><link data-rh="true" rel="alternate" href="https://tchez.dev/blog/vector-database/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://tchez.dev/pt/blog/vector-database","mainEntityOfPage":"https://tchez.dev/pt/blog/vector-database","url":"https://tchez.dev/pt/blog/vector-database","headline":"Como armazenar conhecimento com bancos de dados vetoriais?","name":"Como armazenar conhecimento com bancos de dados vetoriais?","description":"Em um mundo inundado de dados n√£o estruturados, como podemos armazenar n√£o apenas informa√ß√µes, mas conhecimento? Este artigo mergulha nos bancos de dados vetoriais - uma abordagem revolucion√°ria que permite busca baseada em similaridade e compreens√£o sem√¢ntica. Aprenda como vetores e embeddings reformulam o armazenamento de dados, potencializam aplica√ß√µes avan√ßadas de IA e marcam uma mudan√ßa dos bancos de dados tradicionais para sistemas orientados ao conhecimento.","datePublished":"2025-06-12T00:00:00.000Z","author":{"@type":"Person","name":"Marco Ant√¥nio Martins Porto Netto","description":"Full‚ÄëStack Dev & AI¬†Enthusiast","url":"https://github.com/tchez","image":"https://github.com/tchez.png"},"image":{"@type":"ImageObject","@id":"https://tchez.dev/pt/img/vector-database-og-pt.png","url":"https://tchez.dev/pt/img/vector-database-og-pt.png","contentUrl":"https://tchez.dev/pt/img/vector-database-og-pt.png","caption":"title image for the blog post: Como armazenar conhecimento com bancos de dados vetoriais?"},"keywords":["banco de dados vetorial","armazenamento de conhecimento","busca sem√¢ntica","embeddings","intelig√™ncia artificial","PNL","recupera√ß√£o aumentada por gera√ß√£o"],"isPartOf":{"@type":"Blog","@id":"https://tchez.dev/pt/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/pt/blog/rss.xml" title="Brain¬†Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/pt/blog/atom.xml" title="Brain¬†Blog Atom Feed"><link rel="stylesheet" href="/pt/assets/css/styles.70366daf.css">
<script src="/pt/assets/js/runtime~main.d6e1f42f.js" defer="defer"></script>
<script src="/pt/assets/js/main.a7d26c54.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/pt/img/logo.png"><link rel="preload" as="image" href="https://github.com/tchez.png"><div role="region" aria-label="Pular para o conte√∫do principal"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Pular para o conte√∫do principal</a></div><nav aria-label="Menu principal" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar a barra de navega√ß√£o" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/pt/"><div class="navbar__logo"><img src="/pt/img/logo.png" alt="Brain Blog Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/pt/img/logo.png" alt="Brain Blog Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Brain Blog</b></a><a class="navbar__item navbar__link" href="/pt/blog/welcome/">Sobre o Brain Blog</a><a class="navbar__item navbar__link" href="/pt/notes/intro/">Notas</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/pt/blog/">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Portugu√™s</a><ul class="dropdown__menu"><li><a href="/blog/vector-database/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/pt/blog/vector-database/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="pt-BR">Portugu√™s</a></li></ul></div><a href="https://www.linkedin.com/in/tchez/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><a href="https://github.com/tchez/brain-blog" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="modo do sistema" aria-label="Alterar entre os modos claro e escuro (modo modo do sistema ativado)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Navega√ß√£o de postagens recentes do blog"><div class="sidebarItemTitle_pO2u margin-bottom--md">Publicados recentemente</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/pt/blog/vector-database/">Como armazenar conhecimento com bancos de dados vetoriais?</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/pt/blog/dunder-methods/">Voc√™ sabe o que s√£o m√©todos m√°gicos em Python? Dica: Voc√™ usa todos os dias!</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/pt/blog/welcome/">Bem‚Äëvindo ao Brain¬†Blog¬†üéâ</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">Como armazenar conhecimento com bancos de dados vetoriais?</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-06-12T00:00:00.000Z">12 de junho de 2025</time> ¬∑ <!-- -->Leitura de 14 minutos</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/tchez" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/tchez.png" alt="Marco Ant√¥nio Martins Porto Netto"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/tchez" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Marco Ant√¥nio Martins Porto Netto</span></a></div><small class="authorTitle_nd0D" title="Full‚ÄëStack Dev &amp; AI¬†Enthusiast">Full‚ÄëStack Dev &amp; AI¬†Enthusiast</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><blockquote>
<p>Este artigo foi originalmente publicado no <a href="https://www.linkedin.com/pulse/banco-de-dados-vetorial-armazenando-conhecimento-martins-porto-netto-gislf" target="_blank" rel="noopener noreferrer">LinkedIn</a>.</p>
</blockquote>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAYAAAD68A/GAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAnUlEQVR4nE1PMQ6EMAwriIIKha3txsSI+Ad71Ym3wEArMXbrc31KToduiJLItmyLqqoghHiH/nEc0XUd33Vdf7G+79E0DYZhgHMOy7LwzPMMYwwIZzIRrLVIKSHGiOu6cJ4nnufBfd9MllJCKKVYQcrjOJBzRikFIQQQ1rYtu7G11ppV27Zh33d477Gu65uZe5CCyNM08aa8v4L/RT8PllH3L7OOswAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="360"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/pt/assets/ideal-img/article-og-pt.13790a1.640.png" srcset="/pt/assets/ideal-img/article-og-pt.13790a1.640.png 640w,/pt/assets/ideal-img/article-og-pt.20c1eeb.920.png 920w,/pt/assets/ideal-img/article-og-pt.856e10c.1200.png 1200w" width="640" height="360"></noscript></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="como-armazenar-conhecimento-com-bancos-de-dados-vetoriais">Como armazenar conhecimento com bancos de dados vetoriais?<a href="#como-armazenar-conhecimento-com-bancos-de-dados-vetoriais" class="hash-link" aria-label="Link direto para Como armazenar conhecimento com bancos de dados vetoriais?" title="Link direto para Como armazenar conhecimento com bancos de dados vetoriais?">‚Äã</a></h2>
<p><strong>Em um mundo inundado de dados n√£o estruturados, como podemos armazenar n√£o apenas informa√ß√µes, mas conhecimento?</strong></p>
<p>Este artigo explora o conceito de <strong>bancos de dados vetoriais</strong> ‚Äî uma tecnologia revolucion√°ria que permite busca baseada em similaridade e compreens√£o sem√¢ntica. Vamos entender o que s√£o vetores, como s√£o usados em <a href="https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural" target="_blank" rel="noopener noreferrer">Processamento de Linguagem Natural (PNL)</a> e como <strong>embeddings</strong> permitem representa√ß√µes eficientes e contextualizadas da informa√ß√£o. Por fim, exploraremos aplica√ß√µes do mundo real e por que os bancos de dados vetoriais est√£o se tornando essenciais em sistemas modernos de IA.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-ascens√£o-dos-dados-n√£o-estruturados">A Ascens√£o dos Dados N√£o Estruturados<a href="#a-ascens√£o-dos-dados-n√£o-estruturados" class="hash-link" aria-label="Link direto para A Ascens√£o dos Dados N√£o Estruturados" title="Link direto para A Ascens√£o dos Dados N√£o Estruturados">‚Äã</a></h3>
<p>Com o avan√ßo do <a href="https://pt.wikipedia.org/wiki/Big_Data" target="_blank" rel="noopener noreferrer">Big Data</a>, bilh√µes de dispositivos conectados geram informa√ß√µes em tempo real na forma de texto, imagens, v√≠deos e mais. Esses formatos n√£o estruturados n√£o se encaixam bem em tabelas SQL tradicionais e exigem solu√ß√µes de armazenamento mais sofisticadas. √â aqui que os <strong>bancos de dados vetoriais</strong> surgem como uma abordagem inovadora, permitindo buscas baseadas em similaridade e armazenamento de conhecimento a partir de dados complexos.</p>
<p>Antes de mergulharmos em como os bancos de dados vetoriais funcionam, vamos primeiro recapitular os fundamentos dos bancos de dados.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="o-que-√©-um-banco-de-dados">O que √© um Banco de Dados?<a href="#o-que-√©-um-banco-de-dados" class="hash-link" aria-label="Link direto para O que √© um Banco de Dados?" title="Link direto para O que √© um Banco de Dados?">‚Äã</a></h2>
<p>Um <strong>banco de dados</strong> √©, simplificadamente, uma cole√ß√£o organizada de informa√ß√µes que pode ser acessada, gerenciada e atualizada de forma eficiente. Ele atua como uma estrutura que armazena e organiza dados, facilitando consultas e manipula√ß√µes por meio de software especializado.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bancos-de-dados-relacionais">Bancos de Dados Relacionais<a href="#bancos-de-dados-relacionais" class="hash-link" aria-label="Link direto para Bancos de Dados Relacionais" title="Link direto para Bancos de Dados Relacionais">‚Äã</a></h3>
<p>Os <strong>bancos de dados relacionais</strong> s√£o o tipo mais comumente usado. Eles armazenam dados em tabelas organizadas em linhas e colunas ‚Äî onde cada linha representa um registro e cada coluna representa um campo ou atributo. Esse modelo √© ideal para dados estruturados, como registros de clientes, transa√ß√µes banc√°rias ou invent√°rios de produtos.</p>
<p>Um exemplo cl√°ssico √© um banco de dados de clientes com colunas para nome, endere√ßo, n√∫mero de telefone e e-mail. Os bancos de dados relacionais permitem consultas r√°pidas e precisas, como ‚Äúencontrar todos os clientes que fizeram uma compra nos √∫ltimos 30 dias‚Äù, usando uma linguagem conhecida como <a href="https://pt.wikipedia.org/wiki/SQL" target="_blank" rel="noopener noreferrer">SQL (Structured Query Language)</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bancos-de-dados-n√£o-relacionais-nosql">Bancos de Dados N√£o Relacionais (NoSQL)<a href="#bancos-de-dados-n√£o-relacionais-nosql" class="hash-link" aria-label="Link direto para Bancos de Dados N√£o Relacionais (NoSQL)" title="Link direto para Bancos de Dados N√£o Relacionais (NoSQL)">‚Äã</a></h3>
<p>Ao contr√°rio dos bancos de dados relacionais, os <strong>bancos de dados NoSQL</strong> s√£o projetados para lidar com dados n√£o estruturados ou semi-estruturados, oferecendo mais flexibilidade e escalabilidade. Eles armazenam informa√ß√µes em formatos diversos, como documentos JSON, pares chave-valor ou <a href="https://pt.wikipedia.org/wiki/Grafo" target="_blank" rel="noopener noreferrer">grafos</a>. Isso os torna mais adequados para aplica√ß√µes modernas, como plataformas de m√≠dia social ou servi√ßos de streaming.</p>
<p>Por exemplo, um banco de dados NoSQL orientado a documentos pode armazenar dados em formato JSON, permitindo estruturas de dados mais complexas e aninhadas ‚Äî sem exigir um esquema r√≠gido.</p>
<p>Entre as categorias de bancos de dados n√£o relacionais, os <strong>bancos de dados vetoriais</strong> se destacam por sua capacidade de armazenar dados contextualizados ‚Äî tamb√©m conhecidos como <strong>conhecimento</strong>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bancos-de-dados-vetoriais">Bancos de Dados Vetoriais<a href="#bancos-de-dados-vetoriais" class="hash-link" aria-label="Link direto para Bancos de Dados Vetoriais" title="Link direto para Bancos de Dados Vetoriais">‚Äã</a></h3>
<p>Os <strong>bancos de dados vetoriais</strong> introduzem uma abordagem transformadora voltada para armazenar e recuperar dados como <strong>vetores</strong> ‚Äî estruturas matem√°ticas que representam informa√ß√µes em m√∫ltiplas dimens√µes. Ao contr√°rio dos bancos de dados tradicionais que dependem de correspond√™ncia exata, os bancos de dados vetoriais permitem <strong>buscas por similaridade</strong>, que s√£o ideais para recuperar conte√∫dos como textos, imagens ou sons com base em suas caracter√≠sticas.</p>
<p>Isso nos leva a uma pergunta chave: <em>o que √© um vetor?</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="o-que-√©-um-vetor">O que √© um Vetor?<a href="#o-que-√©-um-vetor" class="hash-link" aria-label="Link direto para O que √© um Vetor?" title="Link direto para O que √© um Vetor?">‚Äã</a></h2>
<p>Um <strong>vetor</strong> √© uma estrutura que armazena informa√ß√µes em v√°rias dimens√µes. No caso de um vetor tridimensional, ele possui tr√™s coordenadas ‚Äî <em>(x, y, z)</em> ‚Äî que definem sua posi√ß√£o ou dire√ß√£o em um espa√ßo 3D.</p>
<p>Um exemplo do mundo real √© como as cores s√£o representadas no modelo <a href="https://pt.wikipedia.org/wiki/RGB" target="_blank" rel="noopener noreferrer"><strong>RGB</strong></a> (Vermelho, Verde, Azul). Uma cor √© descrita por tr√™s valores, cada um representando a intensidade de vermelho, verde e azul. Por exemplo, o branco √© <code>[255, 255, 255]</code>, enquanto o preto √© <code>[0, 0, 0]</code>.</p>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAACCAIAAADuA9qHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAASUlEQVR4nAE+AMH/AOKIiOOko+a6ufLIy8i9qqPLysrV5a+tqaOkpba2twDooaHr29ru///1v8S5o4R1t7a+z+v89/Lt7+/z9PV5iS7u2330zwAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="138"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/pt/assets/ideal-img/image-1-pt.ebe3c3b.640.png" srcset="/pt/assets/ideal-img/image-1-pt.ebe3c3b.640.png 640w,/pt/assets/ideal-img/image-1-pt.3215b79.920.png 920w,/pt/assets/ideal-img/image-1-pt.eb1faef.1166.png 1166w" width="640" height="138"></noscript></div>
<br>
<p>Esse conceito se estende para <strong>vetores 4D</strong>, como <a href="https://pt.wikipedia.org/wiki/RGBA" target="_blank" rel="noopener noreferrer"><strong>RGBA</strong></a>, onde o quarto componente ‚ÄúA‚Äù representa o <strong>alpha</strong> (transpar√™ncia). Um vermelho semi-transparente poderia ser <code>[255, 0, 0, 0.5]</code>.</p>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAACCAIAAADuA9qHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAPUlEQVR4nCXJwQ0AEAwFUPuP4mwEcbMI1SDhQPVLeNdnoArgzFmtTd6nEHqMuhYe83uPkZ0rRNwaMYvI7wu2WzgBLoVF0AAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="138"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/pt/assets/ideal-img/image-2-pt.d037018.640.png" srcset="/pt/assets/ideal-img/image-2-pt.d037018.640.png 640w,/pt/assets/ideal-img/image-2-pt.4ef0f29.920.png 920w,/pt/assets/ideal-img/image-2-pt.ac83b77.1166.png 1166w" width="640" height="138"></noscript></div>
<br>
<p>Assim como as cores podem ser representadas por vetores em tr√™s ou quatro dimens√µes, os bancos de dados vetoriais usam vetores para organizar itens como palavras, imagens e sons em espa√ßos multidimensionais, onde a <strong>dist√¢ncia</strong> entre vetores indica similaridade.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="representando-palavras-com-vetores">Representando Palavras com Vetores<a href="#representando-palavras-com-vetores" class="hash-link" aria-label="Link direto para Representando Palavras com Vetores" title="Link direto para Representando Palavras com Vetores">‚Äã</a></h3>
<p>Os vetores s√£o amplamente utilizados para representar informa√ß√µes mais abstratas, como palavras. Em PNL, converter palavras em n√∫meros √© essencial para que as m√°quinas possam entend√™-las e manipul√°-las. Uma das t√©cnicas mais simples √© a <strong>One-Hot Encoding</strong>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="one-hot-encoding">One-Hot Encoding<a href="#one-hot-encoding" class="hash-link" aria-label="Link direto para One-Hot Encoding" title="Link direto para One-Hot Encoding">‚Äã</a></h3>
<p>One-Hot Encoding √© uma t√©cnica onde cada palavra √© transformada em um vetor de zeros e uns. Nesse vetor, cada posi√ß√£o corresponde a uma palavra espec√≠fica no vocabul√°rio, e apenas uma posi√ß√£o cont√©m o valor &quot;1&quot; ‚Äî todas as outras s√£o definidas como &quot;0&quot;.</p>
<p>Vamos considerar um conjunto de quatro palavras: cachorro, gato, p√°ssaro e peixe. Usando One-Hot Encoding, essas palavras seriam representadas da seguinte forma:</p>
<ul>
<li><strong>cachorro:</strong> [1, 0, 0, 0]</li>
<li><strong>gato:</strong> [0, 1, 0, 0]</li>
<li><strong>p√°ssaro:</strong> [0, 0, 1, 0]</li>
<li><strong>peixe:</strong> [0, 0, 0, 1]</li>
</ul>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAIAAADzBuo/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAhklEQVR4nAXBSw7CIBAAUO5/NBNjFy6a6EJj2kI/TIEyfIZhfE91kULFGAMAvXcRCTGs28rMIqIi4e147McOAIhImYb9OW6vGCIRKe7dBbfMy2nPnDMRWbDa6BQTM6vGraTy0d+7GUoptVbvvd3s6N5HBdVaCz5YDz+YEDGl5Jy7wjXBHAn/Aq6Nrad88W0AAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="299"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/pt/assets/ideal-img/image-3-pt.415a446.640.png" srcset="/pt/assets/ideal-img/image-3-pt.415a446.640.png 640w,/pt/assets/ideal-img/image-3-pt.187bbf7.920.png 920w,/pt/assets/ideal-img/image-3-pt.0e7199b.1166.png 1166w" width="640" height="299"></noscript></div>
<br>
<p>Cada vetor cont√©m apenas um &quot;1&quot;, indicando a palavra correspondente, enquanto os &quot;0s&quot; indicam que as outras palavras n√£o est√£o presentes. Embora essa abordagem seja simples e f√°cil de implementar, ela apresenta algumas limita√ß√µes ‚Äî especialmente √† medida que o vocabul√°rio come√ßa a crescer.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="as-limita√ß√µes-da-one-hot-encoding">As Limita√ß√µes da One-Hot Encoding<a href="#as-limita√ß√µes-da-one-hot-encoding" class="hash-link" aria-label="Link direto para As Limita√ß√µes da One-Hot Encoding" title="Link direto para As Limita√ß√µes da One-Hot Encoding">‚Äã</a></h3>
<p>Embora simples, a One-Hot Encoding n√£o captura as rela√ß√µes sem√¢nticas entre as palavras. No exemplo acima, &quot;cachorro&quot; e &quot;gato&quot; s√£o tratados como completamente diferentes, mesmo que ambos sejam animais de estima√ß√£o, tenham quatro patas, duas orelhas e uma cauda. Outra desvantagem aparece em cen√°rios com grandes vocabul√°rios ‚Äî digamos, 10.000 palavras. Nesses casos, cada palavra seria representada por um vetor muito longo com um √∫nico &quot;1&quot; entre 10.000 posi√ß√µes, sem oferecer nenhuma indica√ß√£o de como as palavras se relacionam entre si. Essa inefici√™ncia e falta de informa√ß√£o sem√¢ntica destacam a necessidade de t√©cnicas mais avan√ßadas para representar palavras como vetores de forma mais eficiente.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="representa√ß√µes-avan√ßadas-embeddings">Representa√ß√µes Avan√ßadas: Embeddings<a href="#representa√ß√µes-avan√ßadas-embeddings" class="hash-link" aria-label="Link direto para Representa√ß√µes Avan√ßadas: Embeddings" title="Link direto para Representa√ß√µes Avan√ßadas: Embeddings">‚Äã</a></h3>
<p>Para superar essas limita√ß√µes, foram introduzidos os embeddings ‚Äî representa√ß√µes vetoriais densas e cont√≠nuas de palavras, onde palavras com significados semelhantes s√£o colocadas pr√≥ximas umas das outras no espa√ßo vetorial. Ao contr√°rio da One-Hot Encoding, os embeddings capturam o significado das palavras, posicionando termos relacionados ‚Äî como ‚Äúcachorro‚Äù e ‚Äúgato‚Äù ‚Äî pr√≥ximos uns dos outros no espa√ßo vetorial, uma vez que compartilham caracter√≠sticas comuns.</p>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAIAAADzBuo/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAbElEQVR4nFXLyxKCMAxGYd7//Vy5Q2waxjZQU1vA9Ge8zIjb883pAKA1a0iavSO+Bc3FtuerA92HpTYvy+Xs6CrDqY9+evcfGy8YK0Y1GiaJ+XADYa6O7vwAp41CkWJ/rFojz2mFSA4u5vXLO68KkGyDJ8ySAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="299"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/pt/assets/ideal-img/image-4-pt.b5932d3.640.png" srcset="/pt/assets/ideal-img/image-4-pt.b5932d3.640.png 640w,/pt/assets/ideal-img/image-4-pt.37c506d.920.png 920w,/pt/assets/ideal-img/image-4-pt.83b075a.1166.png 1166w" width="640" height="299"></noscript></div>
<br>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="o-que-s√£o-embeddings">O Que S√£o Embeddings?<a href="#o-que-s√£o-embeddings" class="hash-link" aria-label="Link direto para O Que S√£o Embeddings?" title="Link direto para O Que S√£o Embeddings?">‚Äã</a></h2>
<p>Embeddings s√£o uma forma de representar dados como vetores, onde itens semelhantes s√£o posicionados pr√≥ximos uns dos outros em um espa√ßo multidimensional. Eles s√£o amplamente utilizados em √°reas como PNL para capturar rela√ß√µes entre palavras, imagens ou sons de forma mais eficaz do que m√©todos mais simples, como One-Hot Encoding.</p>
<p>Esses embeddings permitem que dados com caracter√≠sticas semelhantes se agrupem, o que torna a busca por similaridade e o agrupamento de informa√ß√µes relacionadas muito mais eficientes.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="uma-analogia-simples-cores-em-um-espa√ßo-vetorial-3d">Uma Analogia Simples: Cores em um Espa√ßo Vetorial 3D<a href="#uma-analogia-simples-cores-em-um-espa√ßo-vetorial-3d" class="hash-link" aria-label="Link direto para Uma Analogia Simples: Cores em um Espa√ßo Vetorial 3D" title="Link direto para Uma Analogia Simples: Cores em um Espa√ßo Vetorial 3D">‚Äã</a></h3>
<p>Para facilitar a compreens√£o, vamos considerar um exemplo familiar: cores no modelo <strong>RGBA</strong>. Cada cor √© representada por quatro valores ‚Äî as intensidades de vermelho, verde e azul, al√©m de um canal alfa que controla a transpar√™ncia ‚Äî colocando-a em um espa√ßo <strong>quatro-dimensional (4D)</strong>.</p>
<blockquote>
<p>Como n√£o podemos visualizar quatro dimens√µes diretamente, simplificamos plotando apenas os componentes RGB em um espa√ßo 3D. O valor alfa ainda existe, mas n√£o √© representado visualmente nesta vis√£o.</p>
</blockquote>
<p>Por exemplo:</p>
<ul>
<li><strong>Vermelho:</strong> <code>[255, 0, 0, 1]</code></li>
<li><strong>Vermelho Claro:</strong> <code>[255, 0, 0, 0.5]</code></li>
<li><strong>Verde:</strong> <code>[0, 255, 0, 1]</code></li>
<li><strong>Azul:</strong> <code>[0, 0, 255, 1]</code></li>
</ul>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAIAAADzBuo/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAATUlEQVR4nF2NSQqAMBRDe//LdlG0+WPkW8Uhm0DegzSSzCRpY2y9q2meqZ1sq8oBApC5AxCRPy6DGRnv5YPXj3q4X1JhsZiAqd7G830A246UYXZY8P0AAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="299"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/pt/assets/ideal-img/image-5-pt.bab587e.640.png" srcset="/pt/assets/ideal-img/image-5-pt.bab587e.640.png 640w,/pt/assets/ideal-img/image-5-pt.9843105.920.png 920w,/pt/assets/ideal-img/image-5-pt.3f719f0.1166.png 1166w" width="640" height="299"></noscript></div>
<br>
<p>Quando plotamos essas cores em um espa√ßo 3D usando apenas os componentes RGB, podemos ver claramente que <strong>Vermelho</strong> e <strong>Vermelho Claro</strong> aparecem pr√≥ximos um do outro, enquanto <strong>Verde</strong> e <strong>Azul</strong> est√£o localizados mais distantes. Essa proximidade espacial reflete qu√£o semelhantes as cores s√£o ‚Äî neste caso, devido √† sua intensidade vermelha compartilhada.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="representando-palavras-com-embeddings">Representando Palavras com Embeddings<a href="#representando-palavras-com-embeddings" class="hash-link" aria-label="Link direto para Representando Palavras com Embeddings" title="Link direto para Representando Palavras com Embeddings">‚Äã</a></h3>
<p>Agora, vamos aplicar essa ideia a como representamos palavras. Em vez de usar tr√™s ou quatro dimens√µes como no modelo de cores RGB, as palavras s√£o tipicamente representadas em <strong>espa√ßos vetoriais com centenas ou at√© milhares de dimens√µes</strong>. Cada dimens√£o captura algum aspecto ou caracter√≠stica da palavra ‚Äî como seu significado, contexto ou rela√ß√µes com outras palavras.</p>
<p>Por exemplo:</p>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAECAIAAAA4WjmaAAAACXBIWXMAAAsTAAALEwEAmpwYAAAASUlEQVR4nE2MMQ7AIAwD+f8buzM1TYbSQBOnoiCBJ/tOcootbi+AnaRB3S0izBpUS87V+pwaf3pxFNJb5FFdep03Pw8huph56A+1+HX89txxFAAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="254"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/pt/assets/ideal-img/image-6-pt.bbc6cdd.640.png" srcset="/pt/assets/ideal-img/image-6-pt.bbc6cdd.640.png 640w,/pt/assets/ideal-img/image-6-pt.80a3de5.920.png 920w,/pt/assets/ideal-img/image-6-pt.d202cbc.1166.png 1166w" width="640" height="254"></noscript></div>
<br>
<p>No exemplo acima, <strong>&quot;cachorro&quot;</strong> e <strong>&quot;gato&quot;</strong> aparecem pr√≥ximos um do outro no espa√ßo vetorial, porque ambos s√£o animais de estima√ß√£o e compartilham semelhan√ßas contextuais. Por outro lado, <strong>&quot;carro&quot;</strong> e <strong>&quot;floresta&quot;</strong> est√£o posicionados mais distantes devido aos seus significados e padr√µes de uso muito diferentes.</p>
<blockquote>
<p>Ilustrativo apenas ‚Äî nenhum modelo real foi utilizado pra gerar esses vetores.</p>
</blockquote>
<p>Esses <strong>espa√ßos vetoriais de alta dimens√£o</strong> s√£o gerados por <strong>modelos de embedding</strong>, que analisam grandes volumes de texto e aprendem a posicionar palavras com base nos contextos em que aparecem. Quanto mais pr√≥ximas duas palavras est√£o no espa√ßo, mais semanticamente semelhantes elas s√£o.</p>
<p>Essa representa√ß√£o torna poss√≠vel que as m√°quinas raciocinem sobre o significado ‚Äî n√£o apenas reconhe√ßam correspond√™ncias exatas, mas <strong>entendam a rela√ß√£o</strong>. Essa √© uma base fundamental para tarefas modernas de IA, como resposta a perguntas, tradu√ß√£o e busca sem√¢ntica.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="explore-uma-representa√ß√£o-real-de-embedding">Explore uma Representa√ß√£o Real de Embedding<a href="#explore-uma-representa√ß√£o-real-de-embedding" class="hash-link" aria-label="Link direto para Explore uma Representa√ß√£o Real de Embedding" title="Link direto para Explore uma Representa√ß√£o Real de Embedding">‚Äã</a></h3>
<p>Se voc√™ gostaria de ver como os embeddings se parecem na pr√°tica, pode explorar uma visualiza√ß√£o interativa ao vivo usando o <a href="https://projector.tensorflow.org/" target="_blank" rel="noopener noreferrer">TensorFlow Embedding Projector</a>. Esta ferramenta permite que voc√™ <strong>navegue por espa√ßos vetoriais de alta dimens√£o</strong> e observe como palavras, imagens ou outros pontos de dados s√£o organizados com base em suas rela√ß√µes sem√¢nticas.</p>
<p>Voc√™ ver√° algo semelhante ao exemplo abaixo, onde cada palavra √© plotada em um espa√ßo com at√© 200 dimens√µes, reduzido visualmente para 2D ou 3D usando t√©cnicas de redu√ß√£o de dimensionalidade como <a href="https://pt.wikipedia.org/wiki/An%C3%A1lise_de_componentes_principais" target="_blank" rel="noopener noreferrer">PCA</a> ou <a href="https://www.datacamp.com/pt/tutorial/introduction-t-sne" target="_blank" rel="noopener noreferrer">t-SNE</a>.</p>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAIAAAB1kpiRAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAsklEQVR4nAXB226DIBgAYN7/JXq5N1ja3SyLbdKlox4C/KA/KIKoxR3Utskuuuz7yOPxN3+Pn1p21nb9YA0gSufcJX5NQZJ1WYZh/InR2db7oPipSA/eh1JBjBNZbr+Yb1t407VTSgpG6SmpsK5kbuCdlHv2unnytjBYlUoJAC448EIyyrMj6bWvWeND59tGgEzPZ5YmL7vnCrVBRa73dZ37PnQ1Cq0NCC54QT8oyqxt9D/eTJqo3IBxpgAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="393"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/pt/assets/ideal-img/image-7.af13a16.640.png" srcset="/pt/assets/ideal-img/image-7.af13a16.640.png 640w,/pt/assets/ideal-img/image-7.32a0184.902.png 902w" width="640" height="393"></noscript></div>
<br>
<p>Nesta visualiza√ß√£o, cada ponto representa uma palavra, e a proximidade entre eles reflete qu√£o semelhantes seus significados s√£o de acordo com o modelo de embedding. Por exemplo, a palavra <strong>‚Äústore‚Äù</strong> est√° cercada por palavras como <strong>‚Äúshop,‚Äù ‚Äúmarket,‚Äù</strong> e <strong>‚Äúretail‚Äù</strong>, indicando que o modelo aprendeu sua semelhan√ßa contextual a partir de dados textuais em larga escala.</p>
<blockquote>
<p>Esse tipo de espa√ßo de embedding permite que as m√°quinas n√£o apenas reconhe√ßam termos individuais, mas tamb√©m entendam as rela√ß√µes entre eles ‚Äî uma capacidade poderosa para tarefas como busca sem√¢ntica, onde o objetivo √© encontrar informa√ß√µes relevantes com base no significado, em vez de correspond√™ncias exatas.</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-vector-db-works">Como Funciona um Banco de Dados Vetorial?<a href="#how-vector-db-works" class="hash-link" aria-label="Link direto para Como Funciona um Banco de Dados Vetorial?" title="Link direto para Como Funciona um Banco de Dados Vetorial?">‚Äã</a></h2>
<p>Agora que cobrimos os conceitos b√°sicos, podemos entender melhor como os <strong>bancos de dados vetoriais</strong> operam. Um banco de dados vetorial organiza dados na forma de vetores, que ocupam posi√ß√µes em <strong>espa√ßo multidimensional</strong>. O principal objetivo √© permitir a <strong>busca sem√¢ntica</strong> ‚Äî ou seja, encontrar itens semelhantes com base em sua <strong>proximidade vetorial</strong>, em vez de correspond√™ncias exatas como em bancos de dados tradicionais.</p>
<p>Por exemplo, imagine um banco de dados de imagens onde cada imagem √© representada como um vetor que captura suas caracter√≠sticas visuais ‚Äî como cor, forma e textura. Se voc√™ quiser encontrar imagens semelhantes a uma imagem espec√≠fica de um gato, o banco de dados vetorial calcular√° a <strong>dist√¢ncia</strong> entre o vetor da imagem de consulta e os vetores de outras imagens armazenadas. Aqueles com a <strong>menor dist√¢ncia</strong> ser√£o retornados como resultados, uma vez que compartilham caracter√≠sticas semelhantes.</p>
<p>Uma aplica√ß√£o comum desse tipo √© o <strong>reconhecimento facial</strong>, onde a semelhan√ßa entre o vetor de um rosto capturado e o de um rosto registrado pode indicar uma correspond√™ncia potencial.</p>
<p>Mas como exatamente a semelhan√ßa entre vetores √© medida?</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dist√¢ncia-vetorial-e-busca-por-similaridade">Dist√¢ncia Vetorial e Busca por Similaridade<a href="#dist√¢ncia-vetorial-e-busca-por-similaridade" class="hash-link" aria-label="Link direto para Dist√¢ncia Vetorial e Busca por Similaridade" title="Link direto para Dist√¢ncia Vetorial e Busca por Similaridade">‚Äã</a></h3>
<p>Em um banco de dados vetorial, itens com caracter√≠sticas semelhantes s√£o agrupados pr√≥ximos uns dos outros em um <strong>espa√ßo multidimensional</strong>. A &quot;proximidade&quot; ‚Äî ou <strong>similaridade</strong> ‚Äî entre os itens √© determinada por m√©tricas de <strong>dist√¢ncia</strong> espec√≠ficas, como <a href="https://pt.wikipedia.org/wiki/Dist%C3%A2ncia_euclidiana" target="_blank" rel="noopener noreferrer"><strong>dist√¢ncia euclidiana</strong></a> ou <a href="https://pt.wikipedia.org/wiki/Similaridade_por_cosseno" target="_blank" rel="noopener noreferrer"><strong>similaridade por cosseno</strong></a>.</p>
<p>No caso de buscas por palavras, como em nosso exemplo anterior de embeddings, um banco de dados vetorial pode retornar palavras que est√£o semanticamente pr√≥ximas da consulta. Por exemplo, se voc√™ pesquisar pela palavra <strong>&quot;feline&quot;</strong>, o banco de dados pode retornar <strong>&quot;cat,&quot; &quot;tiger,&quot;</strong> ou <strong>&quot;leopard&quot;</strong>, com base em qu√£o pr√≥ximos seus vetores est√£o no espa√ßo sem√¢ntico.</p>
<blockquote>
<p>Esse tipo de correspond√™ncia baseada em vetores permite que os sistemas v√£o al√©m de palavras-chave superficiais e encontrem resultados que est√£o <strong>significativamente relacionados</strong>, mesmo quando as palavras exatas n√£o correspondem ‚Äî uma grande vantagem em aplica√ß√µes modernas de IA.</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="aplica√ß√µes-de-bancos-de-dados-vetoriais">Aplica√ß√µes de Bancos de Dados Vetoriais<a href="#aplica√ß√µes-de-bancos-de-dados-vetoriais" class="hash-link" aria-label="Link direto para Aplica√ß√µes de Bancos de Dados Vetoriais" title="Link direto para Aplica√ß√µes de Bancos de Dados Vetoriais">‚Äã</a></h2>
<p>Os bancos de dados vetoriais j√° est√£o sendo amplamente utilizados para resolver desafios relacionados a <strong>dados n√£o estruturados</strong> em v√°rios dom√≠nios. Aqui est√£o alguns exemplos pr√°ticos:</p>
<ul>
<li>
<p><strong>Busca de Imagens</strong>: Sistemas m√©dicos e plataformas como o Google Imagens usam bancos de dados vetoriais para encontrar imagens visualmente semelhantes com base em caracter√≠sticas como cor, forma e textura ‚Äî o que ajuda em diagn√≥sticos e descoberta de conte√∫do.</p>
</li>
<li>
<p><strong>Recomenda√ß√µes de Produtos</strong>: No com√©rcio eletr√¥nico, os bancos de dados vetoriais sugerem produtos com base em buscas anteriores ou no hist√≥rico de compras do usu√°rio, permitindo uma experi√™ncia de compra mais personalizada.</p>
</li>
<li>
<p><strong>Reconhecimento Facial</strong>: Sistemas de seguran√ßa usam bancos de dados vetoriais para comparar imagens faciais, identificando correspond√™ncias com alta precis√£o ‚Äî tornando a autentica√ß√£o e vigil√¢ncia mais eficazes.</p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation" target="_blank" rel="noopener noreferrer"><strong>RAG (Gera√ß√£o Aumentada por Recupera√ß√£o)</strong></a>: Essa t√©cnica combina a recupera√ß√£o de documentos de bancos de dados vetoriais com as capacidades de gera√ß√£o de respostas de grandes modelos de linguagem (LLMs). Isso permite que esses modelos se especializem em t√≥picos espec√≠ficos sem exigir re-treinamento.</p>
</li>
</ul>
<blockquote>
<p><em>No meu <a href="https://www.linkedin.com/posts/tchez_jornadadeiniciaaexaetocientaedfica-praeamiojovempesquisador-activity-7263597654570369024-2PqS?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAADUhp3MBjeUrhJg0P5LSvpRa8yf14r7iP3Y" target="_blank" rel="noopener noreferrer">trabalho de conclus√£o de curso</a>, utilizei RAG para construir um chatbot focado em sa√∫de mental. O sistema recupera informa√ß√µes relevantes e fornece respostas mais precisas e contextualizadas.</em></p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclus√£o">Conclus√£o<a href="#conclus√£o" class="hash-link" aria-label="Link direto para Conclus√£o" title="Link direto para Conclus√£o">‚Äã</a></h2>
<p>√Ä medida que os dados n√£o estruturados continuam a crescer exponencialmente, <strong>os bancos de dados vetoriais est√£o se tornando essenciais para recuperar informa√ß√µes de forma eficiente e significativa</strong>. Ao permitir a <strong>busca baseada em similaridade</strong> em vez de depender de correspond√™ncias exatas, eles abrem novas possibilidades para interagir com dados complexos de maneiras mais intuitivas e inteligentes.</p>
<p>Desde aplica√ß√µes como <strong>busca de imagens</strong>, <strong>recomenda√ß√µes de produtos</strong> e <strong>reconhecimento facial</strong>, at√© o suporte a t√©cnicas avan√ßadas como <strong>RAG</strong>, os bancos de dados vetoriais est√£o prontos para desempenhar um papel fundamental no futuro da intelig√™ncia artificial. Eles ajudam a preencher a lacuna entre dados brutos e conhecimento acion√°vel ‚Äî impulsionando a inova√ß√£o em diversos setores.</p>
<p>Em um mundo onde contexto e significado importam mais do que nunca, os bancos de dados vetoriais oferecem uma mudan√ßa de paradigma. Ao interpretar dados <strong>sem√¢nticamente</strong>, eles t√™m o potencial de <strong>revolucionar a forma como armazenamos, recuperamos e entendemos informa√ß√µes</strong> ‚Äî conectando os sistemas digitais de hoje com as tecnologias orientadas ao conhecimento de amanh√£.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="refer√™ncias">Refer√™ncias<a href="#refer√™ncias" class="hash-link" aria-label="Link direto para Refer√™ncias" title="Link direto para Refer√™ncias">‚Äã</a></h2>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><strong>Links</strong></summary><div><div class="collapsibleContent_i85q"><ul>
<li><a href="https://www.oracle.com/br/big-data/what-is-big-data" target="_blank" rel="noopener noreferrer">What is Big Data? ‚Äì Oracle</a></li>
<li><a href="https://www.oracle.com/br/database/what-is-database" target="_blank" rel="noopener noreferrer">What is a Database? ‚Äì Oracle</a></li>
<li><a href="https://aws.amazon.com/pt/what-is/database" target="_blank" rel="noopener noreferrer">What is a Database? ‚Äì AWS</a></li>
<li><a href="https://aws.amazon.com/pt/what-is/vector-databases" target="_blank" rel="noopener noreferrer">What is a Vector Database? ‚Äì AWS</a></li>
<li><a href="https://www.elastic.co/pt/what-is/vector-embedding" target="_blank" rel="noopener noreferrer">What is a Vector Embedding? ‚Äì Elastic</a></li>
<li><a href="https://medium.com/turing-talks/word-embedding-fazendo-o-computador-entender-o-significado-das-palavras-92fe22745057" target="_blank" rel="noopener noreferrer">Word Embedding: Making Computers Understand Word Meaning ‚Äì Turing Talks</a></li>
<li><a href="https://developers.google.com/machine-learning/crash-course/embeddings?hl=pt-br" target="_blank" rel="noopener noreferrer">Embeddings ‚Äì Google Machine Learning Crash Course</a></li>
<li><a href="https://aws.amazon.com/pt/what-is/retrieval-augmented-generation" target="_blank" rel="noopener noreferrer">What is Retrieval-Augmented Generation (RAG)? ‚Äì AWS</a></li>
</ul></div></div></details></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Marcadores:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/pt/blog/tags/rag/">rag</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/pt/blog/tags/ai/">ai</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/pt/blog/tags/programming/">programming</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/pt/blog/tags/article/">article</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/tchez/brain-blog/edit/main/blog/2025/06/12-vector-database.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Editar essa p√°gina</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Navega√ß√£o da p√°gina de postagem do blog"><a class="pagination-nav__link pagination-nav__link--next" href="/pt/blog/dunder-methods/"><div class="pagination-nav__sublabel">Postagem mais antiga</div><div class="pagination-nav__label">Voc√™ sabe o que s√£o m√©todos m√°gicos em Python? Dica: Voc√™ usa todos os dias!</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#como-armazenar-conhecimento-com-bancos-de-dados-vetoriais" class="table-of-contents__link toc-highlight">Como armazenar conhecimento com bancos de dados vetoriais?</a><ul><li><a href="#a-ascens√£o-dos-dados-n√£o-estruturados" class="table-of-contents__link toc-highlight">A Ascens√£o dos Dados N√£o Estruturados</a></li></ul></li><li><a href="#o-que-√©-um-banco-de-dados" class="table-of-contents__link toc-highlight">O que √© um Banco de Dados?</a><ul><li><a href="#bancos-de-dados-relacionais" class="table-of-contents__link toc-highlight">Bancos de Dados Relacionais</a></li><li><a href="#bancos-de-dados-n√£o-relacionais-nosql" class="table-of-contents__link toc-highlight">Bancos de Dados N√£o Relacionais (NoSQL)</a></li><li><a href="#bancos-de-dados-vetoriais" class="table-of-contents__link toc-highlight">Bancos de Dados Vetoriais</a></li></ul></li><li><a href="#o-que-√©-um-vetor" class="table-of-contents__link toc-highlight">O que √© um Vetor?</a><ul><li><a href="#representando-palavras-com-vetores" class="table-of-contents__link toc-highlight">Representando Palavras com Vetores</a></li><li><a href="#one-hot-encoding" class="table-of-contents__link toc-highlight">One-Hot Encoding</a></li><li><a href="#as-limita√ß√µes-da-one-hot-encoding" class="table-of-contents__link toc-highlight">As Limita√ß√µes da One-Hot Encoding</a></li><li><a href="#representa√ß√µes-avan√ßadas-embeddings" class="table-of-contents__link toc-highlight">Representa√ß√µes Avan√ßadas: Embeddings</a></li></ul></li><li><a href="#o-que-s√£o-embeddings" class="table-of-contents__link toc-highlight">O Que S√£o Embeddings?</a><ul><li><a href="#uma-analogia-simples-cores-em-um-espa√ßo-vetorial-3d" class="table-of-contents__link toc-highlight">Uma Analogia Simples: Cores em um Espa√ßo Vetorial 3D</a></li><li><a href="#representando-palavras-com-embeddings" class="table-of-contents__link toc-highlight">Representando Palavras com Embeddings</a></li><li><a href="#explore-uma-representa√ß√£o-real-de-embedding" class="table-of-contents__link toc-highlight">Explore uma Representa√ß√£o Real de Embedding</a></li></ul></li><li><a href="#how-vector-db-works" class="table-of-contents__link toc-highlight">Como Funciona um Banco de Dados Vetorial?</a><ul><li><a href="#dist√¢ncia-vetorial-e-busca-por-similaridade" class="table-of-contents__link toc-highlight">Dist√¢ncia Vetorial e Busca por Similaridade</a></li></ul></li><li><a href="#aplica√ß√µes-de-bancos-de-dados-vetoriais" class="table-of-contents__link toc-highlight">Aplica√ß√µes de Bancos de Dados Vetoriais</a></li><li><a href="#conclus√£o" class="table-of-contents__link toc-highlight">Conclus√£o</a></li><li><a href="#refer√™ncias" class="table-of-contents__link toc-highlight">Refer√™ncias</a></li></ul></div></div></div></div></div></div>
</body>
</html>