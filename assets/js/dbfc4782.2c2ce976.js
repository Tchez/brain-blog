"use strict";(self.webpackChunkbrain_blog=self.webpackChunkbrain_blog||[]).push([[8749],{1895:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"vector-database","metadata":{"permalink":"/blog/vector-database","editUrl":"https://github.com/tchez/brain-blog/edit/main/blog/2025/06/12-vector-database.md","source":"@site/blog/2025/06/12-vector-database.md","title":"From Data to Knowledge: The Power of Vector Databases","description":"In a world flooded with unstructured data, how can we store not just information, but knowledge itself? This article dives into vector databases \u2014 a revolutionary approach that enables similarity-based search and semantic understanding. Learn how vectors and embeddings reshape data storage, power advanced AI applications, and mark a shift from traditional databases to knowledge-driven systems.","date":"2025-06-12T00:00:00.000Z","tags":[{"inline":true,"label":"rag","permalink":"/blog/tags/rag"},{"inline":true,"label":"ai","permalink":"/blog/tags/ai"},{"inline":true,"label":"programming","permalink":"/blog/tags/programming"},{"inline":true,"label":"article","permalink":"/blog/tags/article"}],"readingTime":12.87,"hasTruncateMarker":true,"authors":[{"name":"Marco Ant\xf4nio Martins Porto Netto","title":"Full\u2011Stack Dev & AI\xa0Enthusiast","url":"https://github.com/tchez","imageURL":"https://github.com/tchez.png","key":"tchez","page":null}],"frontMatter":{"title":"From Data to Knowledge: The Power of Vector Databases","description":"In a world flooded with unstructured data, how can we store not just information, but knowledge itself? This article dives into vector databases \u2014 a revolutionary approach that enables similarity-based search and semantic understanding. Learn how vectors and embeddings reshape data storage, power advanced AI applications, and mark a shift from traditional databases to knowledge-driven systems.","slug":"vector-database","authors":["tchez"],"tags":["rag","ai","programming","article"],"image":"/img/blog/vector-database/article-og.png","keywords":["vector storage","vector database","embeddings","natural language processing","similarity search","ai applications","knowledge storage"]},"unlisted":false,"nextItem":{"title":"Do you know what magic methods are in Python? Hint: You use them every day!","permalink":"/blog/dunder-methods"}},"content":"import Image from \\"@theme/IdealImage\\";\\nimport ArticleImage from \\"@site/static/img/blog/vector-database/article-og.png\\";\\nimport FirstImage from \\"@site/static/img/blog/vector-database/image-1.png\\";\\nimport SecondImage from \\"@site/static/img/blog/vector-database/image-2.png\\";\\nimport ThirdImage from \\"@site/static/img/blog/vector-database/image-3.png\\";\\nimport FourthImage from \\"@site/static/img/blog/vector-database/image-4.png\\";\\nimport FifthImage from \\"@site/static/img/blog/vector-database/image-5.png\\";\\nimport SixthImage from \\"@site/static/img/blog/vector-database/image-6.png\\";\\nimport SeventhImage from \\"@site/static/img/blog/vector-database/image-7.png\\";\\n\\n<Image img={ArticleImage} alt=\\"Article banner\\" />\\n\\n## From Data to Knowledge: The Power of Vector Databases\\n\\n**In a world flooded with unstructured data, how can we store not just information, but knowledge itself?**\\n\\nThis article explores the rise of **vector databases** \u2014 a revolutionary technology that enables similarity-based search and semantic understanding. We\'ll break down what vectors are, how they\'re used in [Natural Language Processing (NLP)](https://en.wikipedia.org/wiki/Natural_language_processing) and how **embeddings** allow for efficient, contextualized representations of information. Finally, we\u2019ll explore real-world applications and why vector databases are becoming essential in modern AI systems.\\n\\n\x3c!-- truncate --\x3e\\n\\n### The Rise of Unstructured Data\\n\\nWith the advance of [Big Data](https://en.wikipedia.org/wiki/Big_Data), billions of connected devices generate real-time information in the form of text, images, videos, and more. These unstructured formats don\'t fit well into traditional SQL tables and demand more sophisticated storage solutions. This is where **vector databases** emerge as a game-changing approach, enabling similarity-based searches and unlocking knowledge from complex data.\\n\\nBefore we dive into how vector databases work, let\u2019s first recapitulate the fundamentals of databases.\\n\\n## What Is a Database?\\n\\nA **database** is, simply put, an organized collection of information that can be efficiently accessed, managed and updated. It acts as a structure that stores and organizes data, making it easy to query and manipulate using specialized software.\\n\\n### Relational Databases\\n\\n**Relational databases** are the most commonly used type. They store data in tables organized into rows and columns \u2014 where each row represents a record and each column represents a field or attribute. This model is ideal for structured data such as customer records, bank transactions, or product inventories.\\n\\nA classic example is a customer database with columns for name, address, phone number and email. Relational databases enable fast and precise queries like \u201cfind all customers who made a purchase in the last 30 days,\u201d using a language known as [SQL (Structured Query Language)](https://en.wikipedia.org/wiki/SQL).\\n\\n### Non-Relational Databases (NoSQL)\\n\\nUnlike relational databases, **NoSQL databases** are designed to handle unstructured or semi-structured data, offering more flexibility and scalability. They store information in diverse formats such as JSON documents, key-value pairs or [graphs](https://en.wikipedia.org/wiki/Graph). This makes them better suited for modern applications like social-media platforms or streaming services.\\n\\nFor instance, a document-oriented NoSQL database might store data in JSON format, allowing for more complex and nested data structures \u2014 without requiring a rigid schema.\\n\\nAmong the categories of non-relational databases, **vector databases** stand out for their ability to store contextualized data \u2014 also known as **knowledge**.\\n\\n### Vector Databases\\n\\n**Vector databases** introduce a transformative approach tailored to store and retrieve data as **vectors** \u2014 mathematical structures that represent information in multiple dimensions. Unlike traditional databases that rely on exact matching, vector databases enable **similarity searches**, which are ideal for retrieving content like texts, images or sounds based on their characteristics.\\n\\nThis brings us to a key question: _what is a vector?_\\n\\n## What Is a Vector?\\n\\nA **vector** is a structure that stores information across multiple dimensions. In the case of a three-dimensional vector, it has three coordinates \u2014 _(x, y, z)_ \u2014 that define its position or direction in a 3-D space.\\n\\nA real-world example is how colors are represented in the [**RGB**](https://en.wikipedia.org/wiki/RGB) model (Red, Green, Blue). A color is described by three values, each representing the intensity of red, green and blue. For instance, white is `[255, 255, 255]`, while black is `[0, 0, 0]`.\\n\\n<Image img={FirstImage} alt=\\"RGB cube showing color vectors\\" />\\n<br />\\n\\nThis concept extends to **4-D vectors**, such as [**RGBA**](https://en.wikipedia.org/wiki/RGBA), where the fourth component \u201cA\u201d stands for **alpha** (transpar\xeancia). A semi-transparent red poderia ser `[255, 0, 0, 0.5]`.\\n\\n<Image img={SecondImage} alt=\\"RGBA vector illustration with alpha channel\\" />\\n<br />\\n\\nJust as colors can be represented by vectors in three or four dimensions, vector databases use vectors to organize items such as words, images and sounds in multidimensional spaces, where the **distance** between vectors indicates similarity.\\n\\n### Representing Words with Vectors\\n\\nVectors are widely used to represent more abstract information, such as words. In NLP, converting words into numbers is essential for machines to understand and manipulate them. One of the simplest techniques is **One-Hot Encoding**.\\n\\n### One-Hot Encoding\\n\\nOne-Hot Encoding is a technique in which each word is transformed into a vector of zeros and ones. In this vector, each position corresponds to a specific word in the vocabulary, and only one position holds the value \\"1\\" \u2014 all the others are set to \\"0\\".\\n\\nLet\u2019s consider a set of four words: dog, cat, bird, and fish. Using One-Hot Encoding, these words would be represented as follows:\\n\\n- **dog:** [1, 0, 0, 0]\\n- **cat:** [0, 1, 0, 0]\\n- **bird:** [0, 0, 1, 0]\\n- **fish:** [0, 0, 0, 1]\\n\\n<Image img={ThirdImage} alt=\\"One-Hot matrix for four words\\" />\\n<br />\\n\\nEach vector contains only one \\"1\\", indicating the corresponding word, while the \\"0s\\" indicate that the other words are not present. Although this approach is simple and easy to implement, it comes with some limitations \u2014 especially as the vocabulary begins to grow.\\n\\n### The Limitations of One-Hot Encoding\\n\\nAlthough simple, One-Hot Encoding doesn\'t capture semantic relationships between words. In the example above, \\"dog\\" and \\"cat\\" are treated as completely different, even though both are household pets, have four legs, two ears, and a tail. Another drawback appears in scenarios with large vocabularies \u2014 say, 10,000 words. In such cases, each word would be represented by a very long vector with a single \\"1\\" among 10,000 positions, offering no indication of how the words relate to one another. This inefficiency and lack of semantic information highlight the need for more advanced techniques to represent words as vectors in a meaningful way.\\n\\n### Advanced Representations: Embeddings\\n\\nTo overcome these limitations, embeddings were introduced \u2014 dense and continuous vector representations of words, where words with similar meanings are placed close to each other in the vector space. Unlike One-Hot Encoding, embeddings capture the meaning of words, positioning related terms \u2014 like \u201cdog\u201d and \u201ccat\u201d \u2014 near each other in the vector space, since they share common features.\\n\\n<Image img={FourthImage} alt=\\"2-D projection of word clusters\\" />\\n<br />\\n\\n## What Are Embeddings?\\n\\nEmbeddings are a way to represent data as vectors, where similar items are positioned close to one another in a multidimensional space. They are widely used in areas like NLP to capture relationships between words, images, or sounds more effectively than simpler methods like One-Hot Encoding.\\n\\nThese embeddings allow data with similar characteristics to cluster together, which makes similarity search and grouping of related information much more efficient.\\n\\n### A Simple Analogy: Colors in a 3-D Vector Space\\n\\nTo make this easier to understand, let\u2019s consider a familiar example: colors in the **RGBA** model. Each color is represented by four values \u2014 the intensities of red, green, and blue, plus an alpha channel that controls transparency \u2014 placing it in a **four-dimensional (4D)** space.\\n\\n> Since we can\u2019t visualize four dimensions directly, we simplify by plotting just the RGB components in a 3D space. The alpha value still exists, but isn\'t represented visually in this view.\\n\\nFor example:\\n\\n- **Red:** `[255, 0, 0, 1]`\\n- **Light Red:** `[255, 0, 0, 0.5]`\\n- **Green:** `[0, 255, 0, 1]`\\n- **Blue:** `[0, 0, 255, 1]`\\n\\n<Image img={FifthImage} alt=\\"3-D plot of Red, Light-Red, Green and Blue\\" />\\n<br />\\n\\nWhen we plot these colors in a 3D space using only the RGB components, we can clearly see that **Red** and **Light Red** appear close to each other, while **Green** and **Blue** are located farther away. This spatial proximity reflects how similar the colors are \u2014 in this case, due to their shared red intensity.\\n\\n### Representing Words with Embeddings\\n\\nNow, let\u2019s apply this idea to how we represent words. Instead of using three or four dimensions like in the RGB color model, words are typically represented in **vector spaces with hundreds or even thousands of dimensions**. Each dimension captures some aspect or feature of the word \u2014 such as its meaning, context, or relationships with other words.\\n\\nFor example:\\n\\n<Image img={SixthImage} alt=\\"Toy 3-D projection of dog, cat, car and forest\\" />\\n<br />\\n\\nIn the example above, **\\"dog\\"** and **\\"cat\\"** appear close to each other in the vector space, because both are pets and share contextual similarities. On the other hand, **\\"car\\"** and **\\"forest\\"** are positioned farther away due to their very different meanings and usage patterns.\\n\\n> Illustrative only \u2014 no actual model was used to generate this plot.\\n\\nThese **high-dimensional vector spaces** are generated by **embedding models**, which analyze large volumes of text and learn to position words based on the contexts in which they appear. The closer two words are in the space, the more semantically similar they are likely to be.\\n\\nThis representation makes it possible for machines to reason about meaning \u2014 not just recognize exact matches, but **understand relatedness**. That\u2019s a key foundation for modern AI tasks like question answering, translation, and semantic search.\\n\\n### Explore a Real Embedding Representation\\n\\nIf you\u2019d like to see what embeddings look like in practice, you can explore a live, interactive visualization using the [TensorFlow Embedding Projector](https://projector.tensorflow.org/). This tool allows you to **navigate through high-dimensional vector spaces** and observe how words, images, or other data points are organized based on their semantic relationships.\\n\\nYou\'ll see something similar to the example below, where each word is plotted in a space with up to 200 dimensions, reduced visually to 2D or 3D using dimensionality reduction techniques like [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis) ou [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding).\\n\\n<Image\\n  img={SeventhImage}\\n  alt=\\"TensorFlow Embedding Projector showing words near \'store\'\\"\\n/>\\n<br />\\n\\nIn this visualization, each dot represents a word, and the proximity between them reflects how similar their meanings are according to the embedding model. For example, the word **\u201cstore\u201d** is surrounded by words like **\u201cshop,\u201d \u201cmarket,\u201d** and **\u201cretail\u201d**, indicating that the model has learned their contextual similarity from large-scale text data.\\n\\n> This type of embedding space enables machines not only to recognize individual terms, but also to understand relationships between them \u2014 a powerful capability for tasks like semantic search, where the goal is to find relevant information based on meaning rather than exact matches.\\n\\n## How Does a Vector Database Work? {#how-vector-db-works}\\n\\nNow that we\u2019ve covered the basic concepts, we can better understand how **vector databases** operate. A vector database organizes data in the form of vectors, which occupy positions in **multidimensional space**. The main goal is to enable **semantic search** \u2014 that is, finding similar items based on their **vector proximity**, rather than exact matches like in traditional databases.\\n\\nFor example, imagine a database of images where each image is represented as a vector that captures its visual characteristics \u2014 such as color, shape, and texture. If you want to find images similar to a specific picture of a cat, the vector database will compute the **distance** between the query image\'s vector and the vectors of other stored images. Those with the **shortest distance** will be returned as results, since they share similar characteristics.\\n\\nA common real-world application of this is **facial recognition**, where the similarity between the vector of a captured face and that of a registered face can indicate a potential match.\\n\\nBut how exactly is similarity between vectors measured?\\n\\n### Vector Distance and Similarity Search\\n\\nIn a vector database, items with similar features are clustered close to each other in a **multidimensional space**. The \\"closeness\\" \u2014 or **similarity** \u2014 between items is determined by specific **distance metrics**, such as [**Euclidean distance**](https://en.wikipedia.org/wiki/Euclidean_distance) or [**cosine similarity**](https://en.wikipedia.org/wiki/Cosine_similarity).\\n\\nIn the case of word searches, like in our earlier embeddings example, a vector database can return words that are semantically close to the query. For instance, if you search for the word **\\"feline\\"**, the database might return **\\"cat,\\" \\"tiger,\\"** or **\\"leopard\\"**, based on how near their vectors are in the semantic space.\\n\\n> This kind of vector-based matching allows systems to go beyond surface-level keywords and find results that are **meaningfully related**, even when the exact words don\u2019t match \u2014 a major advantage in modern AI applications.\\n\\n## Applications of Vector Databases\\n\\nVector databases are already being widely used to solve challenges related to **unstructured data** across various domains. Here are some practical examples:\\n\\n- **Image Search**: Medical systems and platforms like Google Images use vector databases to find visually similar images based on features like color, shape, and texture \u2014 which helps with diagnoses and content discovery.\\n\\n- **Product Recommendations**: In e-commerce, vector databases suggest products based on past searches or user purchase history, enabling a more personalized shopping experience.\\n\\n- **Facial Recognition**: Security systems use vector databases to compare facial images, identifying matches with high precision \u2014 making authentication and surveillance more effective.\\n\\n- [**RAG (Retrieval-Augmented Generation)**](https://en.wikipedia.org/wiki/Retrieval-Augmented_Generation): This technique combines document retrieval from vector databases with the response generation capabilities of large language models (LLMs). It allows these models to specialize in specific topics without requiring retraining.\\n\\n> _In my [undergraduate thesis](https://www.linkedin.com/posts/tchez_jornadadeiniciaaexaetocientaedfica-praeamiojovempesquisador-activity-7263597654570369024-2PqS?utm_source=share&utm_medium=member_desktop&rcm=ACoAADUhp3MBjeUrhJg0P5LSvpRa8yf14r7iP3Y), I used RAG to build a chatbot focused on mental health. The system retrieves relevant information and provides more accurate and contextualized responses._\\n\\n## Conclusion\\n\\nAs unstructured data continues to grow exponentially, **vector databases are becoming essential for retrieving information efficiently and meaningfully**. By enabling **similarity-based search** rather than relying on exact matches, they open up new possibilities for interacting with complex data in more intuitive and intelligent ways.\\n\\nFrom applications like **image search**, **product recommendations**, and **facial recognition**, to powering advanced techniques such as **RAG**, vector databases are poised to play a foundational role in the future of artificial intelligence. They help bridge the gap between raw data and actionable knowledge \u2014 fueling innovation across industries.\\n\\nIn a world where context and meaning matter more than ever, vector databases offer a paradigm shift. By interpreting data **semantically**, they have the potential to **revolutionize the way we store, retrieve, and understand information** \u2014 connecting today\u2019s digital systems with the knowledge-driven technologies of tomorrow.\\n\\n## References\\n\\n<details>\\n<summary><strong>Links</strong></summary>\\n\\n- [What is Big Data? \u2013 Oracle](https://www.oracle.com/br/big-data/what-is-big-data)\\n- [What is a Database? \u2013 Oracle](https://www.oracle.com/br/database/what-is-database)\\n- [What is a Database? \u2013 AWS](https://aws.amazon.com/pt/what-is/database)\\n- [What is a Vector Database? \u2013 AWS](https://aws.amazon.com/pt/what-is/vector-databases)\\n- [What is a Vector Embedding? \u2013 Elastic](https://www.elastic.co/pt/what-is/vector-embedding)\\n- [Word Embedding: Making Computers Understand Word Meaning \u2013 Turing Talks](https://medium.com/turing-talks/word-embedding-fazendo-o-computador-entender-o-significado-das-palavras-92fe22745057)\\n- [Embeddings \u2013 Google Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/embeddings?hl=pt-br)\\n- [What is Retrieval-Augmented Generation (RAG)? \u2013 AWS](https://aws.amazon.com/pt/what-is/retrieval-augmented-generation)\\n\\n</details>"},{"id":"dunder-methods","metadata":{"permalink":"/blog/dunder-methods","editUrl":"https://github.com/tchez/brain-blog/edit/main/blog/2025/06/11-dunder-methods.md","source":"@site/blog/2025/06/11-dunder-methods.md","title":"Do you know what magic methods are in Python? Hint: You use them every day!","description":"In this article, we will explore the fascinating world of magic methods in Python, their purpose, and how they can enhance your coding experience. Let\'s dive in!","date":"2025-06-11T00:00:00.000Z","tags":[{"inline":true,"label":"python","permalink":"/blog/tags/python"},{"inline":true,"label":"programming","permalink":"/blog/tags/programming"},{"inline":true,"label":"article","permalink":"/blog/tags/article"}],"readingTime":9.89,"hasTruncateMarker":true,"authors":[{"name":"Marco Ant\xf4nio Martins Porto Netto","title":"Full\u2011Stack Dev & AI\xa0Enthusiast","url":"https://github.com/tchez","imageURL":"https://github.com/tchez.png","key":"tchez","page":null}],"frontMatter":{"title":"Do you know what magic methods are in Python? Hint: You use them every day!","description":"In this article, we will explore the fascinating world of magic methods in Python, their purpose, and how they can enhance your coding experience. Let\'s dive in!","slug":"dunder-methods","authors":["tchez"],"tags":["python","programming","article"],"image":"/img/blog/dunder-methods/article-og.png","keywords":["dunder methods","magic methods","python","programming","article"]},"unlisted":false,"prevItem":{"title":"From Data to Knowledge: The Power of Vector Databases","permalink":"/blog/vector-database"},"nextItem":{"title":"Welcome to Brain\xa0Blog\xa0\ud83c\udf89","permalink":"/blog/welcome"}},"content":"> This article was originally published on [LinkedIn](https://www.linkedin.com/pulse/voc%25C3%25AA-sabe-o-que-s%25C3%25A3o-m%25C3%25A9todos-m%25C3%25A1gicos-em-python-dica-os-marco-ant%25C3%25B4nio-zcgbf).\\n\\n![Dunder Methods](/img/blog/dunder-methods/article-og.png)\\n\\n## Do you know what magic methods are in Python? Hint: You use them every day!\\n\\nA few years ago, when I was learning to use the Django framework (the first framework I ever learned), I came across a peculiar characteristic of Python classes: the constructor method has to follow a specific pattern \u2014 it must be identified by double underscores (\\\\_\\\\_) before and after the word `init`. That struck me as odd; why this specific structure?\\n\\n\x3c!-- truncate --\x3e\\n\\n```python\\nclass MyClass:\\n    def __init__(self): # This is the constructor method\\n        ...\\n```\\n\\nTrying to understand where these \'different\' functions came from, I found out that in the world of Python, there are several methods that follow this \'dunder\' pattern (a nickname derived from Double UNDERscore). These methods aren\u2019t just common \u2014 they\u2019re special and fundamental to the language, known as dunder methods or magic methods.\\n\\nOK, but what do these methods actually do? What makes them \'magic\'?\\n\\nThose were some of the questions that led me to study them more deeply and write this article. Hope you enjoy it :)\\n\\n---\\n\\n## What are dunder methods?\\n\\nIn the world of programming, we often come across concepts that seem complex at first, but once understood, make perfect sense. A great example of this in Python is _dunder methods_.\\n\\nSo, what exactly are these methods? As mentioned earlier, the word \'dunder\' refers to the double underscore notation at the beginning and end of the names of these special methods. For instance, `__init__` for a class constructor, or `__str__` for the string representation of an object.\\n\\n> P.S. Some Python purists don\u2019t like calling the `__init__` method a constructor, since technically it\u2019s an initializer. However, for the sake of simplicity, we\u2019ll refer to it as a constructor throughout this article.\\n\\nThese methods aren\u2019t called directly by name. Instead, Python calls them internally when certain actions are performed. For example, when we add two objects using the `+` operator, Python internally calls the `__add__` method, which handles the logic of adding one value to another.\\n\\n> Still a bit confusing? Let me give you some examples to make it clearer!\\n\\nImagine you\'re building a class to represent a book in a library. To do that, you\u2019ll need to implement the `__init__` method, which acts as a constructor, setting up initial attributes like title, author, and page count:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, pages):\\n        self.title = title\\n        self.author = author\\n        self.pages = pages\\n```\\n\\nWhat happens when you try to add two `Book` objects together? You might expect them to combine in some way, but Python doesn\'t know how to handle that operation by default:\\n\\n```python\\nbook1 = Book(\\"First Book\\", \\"Author A\\", 100)\\nbook2 = Book(\\"Second Book\\", \\"Author B\\", 200)\\n\\nprint(book1 + book2)\\n```\\n\\nThis will raise a `TypeError` because Python doesn\'t know how to add two `Book` objects together. This code will output:\\n\\n```python\\n>>> TypeError: unsupported operand type(s) for +: \'Book\' and \'Book\'\\n```\\n\\nTo make this operation work, you can define the `__add__` method in your `Book` class. This method will specify how two `Book` objects should be added together. For example, you might want to add their page counts:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, pages):\\n        self.title = title\\n        self.author = author\\n        self.pages = pages\\n\\n    def __add__(self, other):\\n        return self.pages + other.pages\\n```\\n\\nNow, when you try to add two `Book` objects, Python will call the `__add__` method, in this case, summing their page counts. This is how you can customize the behavior of operators for your own classes.\\n\\n```python\\nbook1 = Book(\\"First Book\\", \\"Author A\\", 100)\\nbook2 = Book(\\"Second Book\\", \\"Author B\\", 200)\\n\\nprint(book1 + book2) # This will output: 300\\n```\\n\\n**This behavior isn\'t limited to just the addition operator!**\\n\\nActually, the most operators in Python can be customized using dunder methods. For example, you can define how your class behaves with the `==` operator by implementing the `__eq__` method, or with the `-` operator by implementing the `__sub__` method. A good example of this is the `in` operator, when we verify if some `value` is `in` a `list`, behind the scenes, Python is calling the `__contains__` method of the list class, passing the `value` as an argument. See the example below:\\n\\n```python\\nmy_list = [1, 2, 3, 4, 5]\\n\\nprint(3 in my_list)  # This will output: True\\nprint(my_list.__contains__(3))  # This will also output: True\\n\\nprint(6 in my_list)  # This will output: False\\nprint(my_list.__contains__(6))  # This will also output: False\\n```\\n\\n## More examples of dunder methods\\n\\nNow that you have a basic understanding of what dunder methods are and how they work, let\'s see some more examples of their usage, still applied to the `Book` class:\\n\\n### `__str__`: Customizing prints\\n\\nFollowing the previous example, what happens when you try to print a `Book` object? By default, Python will show something like `<__main__.Book object at 0x...>`, which isn\'t very informative:\\n\\n```python\\nbook1 = Book(\\"First Book\\", \\"Author A\\", 100)\\nprint(book1)\\n```\\n\\nThis will output something like:\\n\\n```python\\n>>> <__main__.Book object at 0x7f8c1b0d0>\\n```\\n\\nIf you\'re wondering whether it\'s possible to customize this output, making the representation more user-friendly, yes, it is! You just need to implement the magic method called `__str__` in your class. This method allows you to define how your object should be represented as a _string_. So, let\'s go ahead and implement it:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, pages):\\n        self.title = title\\n        self.author = author\\n        self.pages = pages\\n\\n    def __str__(self):\\n        return f\\"{self.title} by {self.author}, {self.pages} pages\\"\\n```\\n\\nNow, when you print a `Book` object, it will display the title, author, and page count in a more readable format:\\n\\n```python\\nbook1 = Book(\\"First Book\\", \\"Author A\\", 100)\\nprint(book1) # This will output: First Book by Author A, 100 pages\\n```\\n\\n### `__eq__`: Customizing equality checks\\n\\nWhat if you want to check if two `Book` objects are considered equal? By default, Python checks if they are the same object in memory, which might not be what you want. To customize this behavior, you can implement the `__eq__` method:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, pages):\\n        self.title = title\\n        self.author = author\\n        self.pages = pages\\n\\n    def __eq__(self, other):\\n        return (self.title == other.title and\\n                self.author == other.author and\\n                self.pages == other.pages)\\n```\\n\\nNow, you can compare two `Book` objects for equality based on their attributes:\\n\\n```python\\nbook1 = Book(\\"First Book\\", \\"Author A\\", 100)\\nbook2 = Book(\\"Second Book\\", \\"Author B\\", 200)\\nbook3 = Book(\\"First Book\\", \\"Author A\\", 100)\\n\\nprint(book1 == book2)  # This will output: False\\nprint(book1 == book3)  # This will output: True\\nprint(book3.__eq__(book1))  # This will output: True\\n```\\n\\n### `__len__`: Customizing length checks\\n\\nWhat if you want to check how many pages a book has? You can manually check the `pages` attribute, but you can also implement the `__len__` method to allow the use of the built-in `len()` function:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, pages):\\n        self.title = title\\n        self.author = author\\n        self.pages = pages\\n\\n    def __len__(self):\\n        return self.pages\\n```\\n\\nNow, you can use the `len()` function on a `Book` object:\\n\\n```python\\nbook1 = Book(\\"First Book\\", \\"Author A\\", 100)\\nprint(len(book1))  # This will output: 100\\n```\\n\\n### `__getitem__`: Customizing item access\\n\\nLastly, what if you want to access a specific attribute of a `Book` object using indexing, like `book[0]` for the title? You can implement the `__getitem__` method:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, pages):\\n        self.title = title\\n        self.author = author\\n        self.pages = pages\\n\\n    def __getitem__(self, index):\\n        if index == 0:\\n            return self.title\\n        elif index == 1:\\n            return self.author\\n        elif index == 2:\\n            return self.pages\\n        else:\\n            raise IndexError(\\"Index out of range\\")\\n```\\n\\nNow, you can access the title, author, and pages of a `Book` object using indexing:\\n\\n```python\\nbook1 = Book(\\"First Book\\", \\"Author A\\", 100)\\nprint(book1[0])  # This will output: First Book\\nprint(book1[1])  # This will output: Author A\\nprint(book1[2])  # This will output: 100\\n```\\n\\n## Conclusion\\n\\nThese were just a few examples that highlight the power and flexibility of dunder methods in Python. With them, you can shape the behavior of your classes and objects in ways that align with the language\'s syntax and paradigms, making your code more intuitive and \'Pythonic\'.\\n\\nSo, next time you\'re designing a Python class, remember the magic of dunder methods and how they can enrich your abstractions!\\n\\nBellow, I\'ll leave a list of some of the most commonly used dunder methods in Python, each linked to the official documentation for further reading:\\n\\n- [`__init__`](https://docs.python.org/3/reference/datamodel.html#object.__init__): The constructor method, called when an object is created.\\n- [`__add__`](https://docs.python.org/3/reference/datamodel.html#object.__add__): Defines the behavior of the addition operator (`+`).\\n- [`__contains__`](https://docs.python.org/3/reference/datamodel.html#object.__contains__): Defines the behavior of the `in` operator for an object.\\n- [`__str__`](https://docs.python.org/3/reference/datamodel.html#object.__str__): Defines the string representation of an object, used by the `print()` function.\\n- [`__eq__`](https://docs.python.org/3/reference/datamodel.html#object.__eq__): Defines the behavior of the equality operator (`==`).\\n- [`__len__`](https://docs.python.org/3/reference/datamodel.html#object.__len__): Defines the behavior of the `len()` function for an object.\\n- [`__getitem__`](https://docs.python.org/3/reference/datamodel.html#object.__getitem__): Defines the behavior of indexing an object (e.g., `obj[key]`).\\n- [`__setitem__`](https://docs.python.org/3/reference/datamodel.html#object.__setitem__): Defines the behavior of setting an item in an object (e.g., `obj[key] = value`).\\n- [`__delitem__`](https://docs.python.org/3/reference/datamodel.html#object.__delitem__): Defines the behavior of deleting an item from an object (e.g., `del obj[key]`).\\n- [`__repr__`](https://docs.python.org/3/reference/datamodel.html#object.__repr__): Defines the official string representation of an object, used by the `repr()` function.\\n- [`__ne__`](https://docs.python.org/3/reference/datamodel.html#object.__ne__): Defines the behavior of the inequality operator (`!=`).\\n- [`__lt__`](https://docs.python.org/3/reference/datamodel.html#object.__lt__): Defines the behavior of the less than operator (`<`).\\n- [`__le__`](https://docs.python.org/3/reference/datamodel.html#object.__le__): Defines the behavior of the less than or equal to operator (`<=`).\\n- [`__gt__`](https://docs.python.org/3/reference/datamodel.html#object.__gt__): Defines the behavior of the greater than operator (`>`).\\n- [`__ge__`](https://docs.python.org/3/reference/datamodel.html#object.__ge__): Defines the behavior of the greater than or equal to operator (`>=`).\\n- [`__sub__`](https://docs.python.org/3/reference/datamodel.html#object.__sub__): Defines the behavior of the subtraction operator (`-`).\\n- [`__mul__`](https://docs.python.org/3/reference/datamodel.html#object.__mul__): Defines the behavior of the multiplication operator (`*`).\\n- [`__truediv__`](https://docs.python.org/3/reference/datamodel.html#object.__truediv__): Defines the behavior of the true division operator (`/`).\\n- [`__bool__`](https://docs.python.org/3/reference/datamodel.html#object.__bool__): Defines the truth value of an object, used by the `bool()` function.\\n- [`__iter__`](https://docs.python.org/3/reference/datamodel.html#object.__iter__): Defines the behavior of an object when used in a loop or with the `iter()` function.\\n- [`__next__`](https://docs.python.org/3/reference/datamodel.html#object.__next__): Defines the behavior of the `next()` function for an object, allowing it to be iterable.\\n- [`__enter__`](https://docs.python.org/3/reference/datamodel.html#object.__enter__): Defines the behavior of an object when used in a `with` statement, allowing it to set up a context.\\n- [`__exit__`](https://docs.python.org/3/reference/datamodel.html#object.__exit__): Defines the behavior of an object when exiting a `with` statement, allowing it to clean up resources.\\n- [`__hash__`](https://docs.python.org/3/reference/datamodel.html#object.__hash__): Defines the behavior of the `hash()` function for an object, allowing it to be used in hash-based collections like sets and dictionaries.\\n- [`__del__`](https://docs.python.org/3/reference/datamodel.html#object.__del__): Defines the behavior of an object when it is about to be destroyed, allowing for cleanup actions.\\n\\nI hope this article has shed some light on the fascinating world of dunder methods in Python. If you have any questions or want to share your experiences with dunder methods, feel free to get in touch! Happy coding!\\n\\n## References\\n\\n<details>\\n<summary><strong>Links</strong></summary>\\n\\n- [Python Official Documentation - Data Model](https://docs.python.org/3/reference/datamodel.html)\\n- [Dunder methods | Pydon\'t \ud83d\udc0d](https://mathspp.com/blog/pydonts/dunder-methods)\\n- [Dunder methods in Python, really crazy functions](https://nitesh-yadav.medium.com/dunder-methods-in-python-really-crazy-functions-3455ecb6472d)\\n\\n</details>"},{"id":"welcome","metadata":{"permalink":"/blog/welcome","editUrl":"https://github.com/tchez/brain-blog/edit/main/blog/2025/05/04-welcome.md","source":"@site/blog/2025/05/04-welcome.md","title":"Welcome to Brain\xa0Blog\xa0\ud83c\udf89","description":"My personal place to share ideas and dump structured knowledge.","date":"2025-05-04T00:00:00.000Z","tags":[{"inline":true,"label":"blog","permalink":"/blog/tags/blog"}],"readingTime":1.03,"hasTruncateMarker":true,"authors":[{"name":"Marco Ant\xf4nio Martins Porto Netto","title":"Full\u2011Stack Dev & AI\xa0Enthusiast","url":"https://github.com/tchez","imageURL":"https://github.com/tchez.png","key":"tchez","page":null}],"frontMatter":{"title":"Welcome to Brain\xa0Blog\xa0\ud83c\udf89","description":"My personal place to share ideas and dump structured knowledge.","slug":"welcome","authors":["tchez"],"tags":["blog"],"image":"/img/logo-og.png","keywords":["brain blog","second brain","knowledge vault","learning","study notes"]},"unlisted":false,"prevItem":{"title":"Do you know what magic methods are in Python? Hint: You use them every day!","permalink":"/blog/dunder-methods"}},"content":"![Brain\xa0Blog](/img/logo-og.png)\\n\\nHello, world! \ud83d\udc4b\\n\\n\x3c!-- TODO: Adicionar link para o about me depois --\x3e\\n\\nI\u2019m **[Marco\xa0Ant\xf4nio](https://www.linkedin.com/in/tchez)** and this is my **Brain\xa0Blog**.\\n\\nThis first post is a quick tour of what you\u2019ll find here.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Why \u201cBrain\xa0Blog\u201d?\\n\\n> _\u201cThose who teach learn while teaching, and those who learn teach while learning.\u201d_\\n> \u2014 Paulo Freire (Translated from Portuguese)\\n\\nBrain\xa0Blog is a public backup of my brain where I capture study notes,\\norganize references and document learning journeys.\\n\\n### Content structure\\n\\nimport Tabs from \\"@theme/Tabs\\";\\nimport TabItem from \\"@theme/TabItem\\";\\n\\n<Tabs defaultValue=\\"blog\\">\\n  <TabItem value=\\"blog\\" label=\\"Blog\\">\\n    <br/>\\n    > My personal stream of ideas and experience.\\n    \\n    You\u2019ll read articles, tutorials and reflections on topics that excite me,\\n    plus lessons learned from real\u2011world projects.\\n  </TabItem>\\n  <TabItem value=\\"notes\\" label=\\"Notes\\">\\n    <br/>\\n    > A structured knowledge vault.\\n    \\n    I publish notes, summaries and references from everything I study,\\n    turning them into a reusable base.\\n    \\n    Notes are split into three sections:\\n    \\n    - **[Foundations](/notes/foundations/intro)** \u2013 core explanations of fundamentals (math, algorithms, protocols\u2026).\\n    - **[Projects](/notes/projects/intro)** \u2013 write\u2011ups of things I\u2019m building or ideas I\u2019m exploring.\\n    - **[Journeys](/notes/journeys/intro)** \u2013 step\u2011by\u2011step road\u2011maps of mastering a specific topic, linking to resources and notes.\\n  </TabItem>\\n</Tabs>"}]}}')}}]);