(self.webpackChunkbrain_blog=self.webpackChunkbrain_blog||[]).push([[414],{791:(e,a,s)=>{e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:s.p+"assets/ideal-img/article-og.2767017.640.png 640w,"+s.p+"assets/ideal-img/article-og.7dd2e07.920.png 920w,"+s.p+"assets/ideal-img/article-og.7d655f3.1200.png 1200w",images:[{path:s.p+"assets/ideal-img/article-og.2767017.640.png",width:640,height:360},{path:s.p+"assets/ideal-img/article-og.7dd2e07.920.png",width:920,height:518},{path:s.p+"assets/ideal-img/article-og.7d655f3.1200.png",width:1200,height:675}],src:s.p+"assets/ideal-img/article-og.2767017.640.png",placeholder:void 0,width:640,height:360}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAYAAAD68A/GAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAo0lEQVR4nDWOuwqFQAwF4xMRXwhrYaOCX2An2PghgmIngqWfP5JcbnFgkx0yRzzPQ+P7viUMQ6qqIssyoigiCAJEBNGFAjrEcUxd1wamaWqQ/ukhGYaB67rYto193zmOg+d5eN+X8zy57xvnHFIUBW3b0vc90zSxLAvrujLPM+M40nUdypg6SRKL6lSt0RrWTeSnViDPc8qypGkaeyv0722QCB9tUk3gQY4M9wAAAABJRU5ErkJggg=="}},1287:(e,a,s)=>{e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:s.p+"assets/ideal-img/image-7.af13a16.640.png 640w,"+s.p+"assets/ideal-img/image-7.32a0184.902.png 902w",images:[{path:s.p+"assets/ideal-img/image-7.af13a16.640.png",width:640,height:393},{path:s.p+"assets/ideal-img/image-7.32a0184.902.png",width:902,height:554}],src:s.p+"assets/ideal-img/image-7.af13a16.640.png",placeholder:void 0,width:640,height:393}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAIAAAB1kpiRAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAsklEQVR4nAXB226DIBgAYN7/JXq5N1ja3SyLbdKlox4C/KA/KIKoxR3Utskuuuz7yOPxN3+Pn1p21nb9YA0gSufcJX5NQZJ1WYZh/InR2db7oPipSA/eh1JBjBNZbr+Yb1t407VTSgpG6SmpsK5kbuCdlHv2unnytjBYlUoJAC448EIyyrMj6bWvWeND59tGgEzPZ5YmL7vnCrVBRa73dZ37PnQ1Cq0NCC54QT8oyqxt9D/eTJqo3IBxpgAAAABJRU5ErkJggg=="}},1402:(e,a,s)=>{e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:s.p+"assets/ideal-img/image-2.3d33e6c.640.png 640w,"+s.p+"assets/ideal-img/image-2.b3e0325.920.png 920w,"+s.p+"assets/ideal-img/image-2.f4578cf.1166.png 1166w",images:[{path:s.p+"assets/ideal-img/image-2.3d33e6c.640.png",width:640,height:138},{path:s.p+"assets/ideal-img/image-2.b3e0325.920.png",width:920,height:199},{path:s.p+"assets/ideal-img/image-2.f4578cf.1166.png",width:1166,height:252}],src:s.p+"assets/ideal-img/image-2.3d33e6c.640.png",placeholder:void 0,width:640,height:138}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAACCAIAAADuA9qHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAPklEQVR4nCXJuwkAIAwFQPffJZUjSFoH8RMQNBCIPkGvvYBzAGzVRVRTKswz522GJ/x21RKj9C5jNBF3/30BuHc4DW+0o5AAAAAASUVORK5CYII="}},1865:(e,a,s)=>{e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:s.p+"assets/ideal-img/image-3.edca5ba.640.png 640w,"+s.p+"assets/ideal-img/image-3.cf34687.920.png 920w,"+s.p+"assets/ideal-img/image-3.d9affd3.1166.png 1166w",images:[{path:s.p+"assets/ideal-img/image-3.edca5ba.640.png",width:640,height:299},{path:s.p+"assets/ideal-img/image-3.cf34687.920.png",width:920,height:429},{path:s.p+"assets/ideal-img/image-3.d9affd3.1166.png",width:1166,height:544}],src:s.p+"assets/ideal-img/image-3.edca5ba.640.png",placeholder:void 0,width:640,height:299}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAIAAADzBuo/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAgUlEQVR4nBXJSwrCMBAA0Nz/am6KiAiKGwWpNOk0mU+SyUzEt33B3W0aACDinNPdpdWYopn59MBDTmk58gEAzDzaOMfrIz0pkw4N5ia9wg6YUYeaGTKlPWlTdw9m1qS9tveyXXprvXcsCAlu+R57+jcRZS6fsoqIqhJRFVnLl4f8AGwAjxGma5geAAAAAElFTkSuQmCC"}},3598:(e,a,s)=>{e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:s.p+"assets/ideal-img/image-6.0b60299.640.png 640w,"+s.p+"assets/ideal-img/image-6.9efa731.920.png 920w,"+s.p+"assets/ideal-img/image-6.e50d853.1166.png 1166w",images:[{path:s.p+"assets/ideal-img/image-6.0b60299.640.png",width:640,height:254},{path:s.p+"assets/ideal-img/image-6.9efa731.920.png",width:920,height:365},{path:s.p+"assets/ideal-img/image-6.e50d853.1166.png",width:1166,height:462}],src:s.p+"assets/ideal-img/image-6.0b60299.640.png",placeholder:void 0,width:640,height:254}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAECAIAAAA4WjmaAAAACXBIWXMAAAsTAAALEwEAmpwYAAAARUlEQVR4nE2KsQ3AIBAD2X/GLIAUgUJBSP5tIwpeXOc7Jx3QTeRpkiS4AZDk/nN8I2ffp5W5B8Fe3t5amJUDGO/rKbVGnsBadlH2AdzdAAAAAElFTkSuQmCC"}},6460:(e,a,s)=>{e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:s.p+"assets/ideal-img/image-4.8c7f92e.640.png 640w,"+s.p+"assets/ideal-img/image-4.cd53446.920.png 920w,"+s.p+"assets/ideal-img/image-4.ab95381.1166.png 1166w",images:[{path:s.p+"assets/ideal-img/image-4.8c7f92e.640.png",width:640,height:299},{path:s.p+"assets/ideal-img/image-4.cd53446.920.png",width:920,height:429},{path:s.p+"assets/ideal-img/image-4.ab95381.1166.png",width:1166,height:544}],src:s.p+"assets/ideal-img/image-4.8c7f92e.640.png",placeholder:void 0,width:640,height:299}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAIAAADzBuo/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAZ0lEQVR4nFWLwRJAMAwF/f8HurnRtIxEUdJM2xjlwDvsYXdeo3UpF44CA0xIzJIkPb65UQpxthShs6ZH0/Zol+o/2UUdWcc9w+AJw+etOns2sLlD3ZpgZjzzL287o/Or6EIBDQZ58wXCY5CUpJmE9gAAAABJRU5ErkJggg=="}},7006:e=>{"use strict";e.exports=JSON.parse('{"permalink":"/blog/vector-database","editUrl":"https://github.com/tchez/brain-blog/edit/main/blog/2025/06/12-vector-database.md","source":"@site/blog/2025/06/12-vector-database.md","title":"From Data to Knowledge: The Power of Vector Databases","description":"In a world flooded with unstructured data, how can we store not just information, but knowledge itself? This article dives into vector databases \u2014 a revolutionary approach that enables similarity-based search and semantic understanding. Learn how vectors and embeddings reshape data storage, power advanced AI applications, and mark a shift from traditional databases to knowledge-driven systems.","date":"2025-06-12T00:00:00.000Z","tags":[{"inline":true,"label":"rag","permalink":"/blog/tags/rag"},{"inline":true,"label":"ai","permalink":"/blog/tags/ai"},{"inline":true,"label":"programming","permalink":"/blog/tags/programming"},{"inline":true,"label":"article","permalink":"/blog/tags/article"}],"readingTime":12.87,"hasTruncateMarker":true,"authors":[{"name":"Marco Ant\xf4nio Martins Porto Netto","title":"Full\u2011Stack Dev & AI\xa0Enthusiast","url":"https://github.com/tchez","imageURL":"https://github.com/tchez.png","key":"tchez","page":null}],"frontMatter":{"title":"From Data to Knowledge: The Power of Vector Databases","description":"In a world flooded with unstructured data, how can we store not just information, but knowledge itself? This article dives into vector databases \u2014 a revolutionary approach that enables similarity-based search and semantic understanding. Learn how vectors and embeddings reshape data storage, power advanced AI applications, and mark a shift from traditional databases to knowledge-driven systems.","slug":"vector-database","authors":["tchez"],"tags":["rag","ai","programming","article"],"image":"/img/vector-database-og.png","keywords":["vector storage","vector database","embeddings","natural language processing","similarity search","ai applications","knowledge storage"]},"unlisted":false,"nextItem":{"title":"Do you know what magic methods are in Python? Hint: You use them every day!","permalink":"/blog/dunder-methods"}}')},8506:(e,a,s)=>{"use strict";s.r(a),s.d(a,{assets:()=>R,contentTitle:()=>k,default:()=>I,frontMatter:()=>y,metadata:()=>t,toc:()=>S});var t=s(7006),i=s(4848),n=s(8453),r=s(547),o=s(791),d=s.n(o),l=s(9713),c=s.n(l),h=s(1402),g=s.n(h),p=s(1865),m=s.n(p),u=s(6460),w=s.n(u),A=s(9349),b=s.n(A),x=s(3598),f=s.n(x),j=s(1287),v=s.n(j);const y={title:"From Data to Knowledge: The Power of Vector Databases",description:"In a world flooded with unstructured data, how can we store not just information, but knowledge itself? This article dives into vector databases \u2014 a revolutionary approach that enables similarity-based search and semantic understanding. Learn how vectors and embeddings reshape data storage, power advanced AI applications, and mark a shift from traditional databases to knowledge-driven systems.",slug:"vector-database",authors:["tchez"],tags:["rag","ai","programming","article"],image:"/img/vector-database-og.png",keywords:["vector storage","vector database","embeddings","natural language processing","similarity search","ai applications","knowledge storage"]},k=void 0,R={authorsImageUrls:[void 0]},S=[{value:"From Data to Knowledge: The Power of Vector Databases",id:"from-data-to-knowledge-the-power-of-vector-databases",level:2},{value:"The Rise of Unstructured Data",id:"the-rise-of-unstructured-data",level:3},{value:"What Is a Database?",id:"what-is-a-database",level:2},{value:"Relational Databases",id:"relational-databases",level:3},{value:"Non-Relational Databases (NoSQL)",id:"non-relational-databases-nosql",level:3},{value:"Vector Databases",id:"vector-databases",level:3},{value:"What Is a Vector?",id:"what-is-a-vector",level:2},{value:"Representing Words with Vectors",id:"representing-words-with-vectors",level:3},{value:"One-Hot Encoding",id:"one-hot-encoding",level:3},{value:"The Limitations of One-Hot Encoding",id:"the-limitations-of-one-hot-encoding",level:3},{value:"Advanced Representations: Embeddings",id:"advanced-representations-embeddings",level:3},{value:"What Are Embeddings?",id:"what-are-embeddings",level:2},{value:"A Simple Analogy: Colors in a 3-D Vector Space",id:"a-simple-analogy-colors-in-a-3-d-vector-space",level:3},{value:"Representing Words with Embeddings",id:"representing-words-with-embeddings",level:3},{value:"Explore a Real Embedding Representation",id:"explore-a-real-embedding-representation",level:3},{value:"How Does a Vector Database Work?",id:"how-vector-db-works",level:2},{value:"Vector Distance and Similarity Search",id:"vector-distance-and-similarity-search",level:3},{value:"Applications of Vector Databases",id:"applications-of-vector-databases",level:2},{value:"Conclusion",id:"conclusion",level:2},{value:"References",id:"references",level:2}];function E(e){const a={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,n.R)(),...e.components},{Details:s}=a;return s||function(e,a){throw new Error("Expected "+(a?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.A,{img:d(),alt:"Article banner"}),"\n",(0,i.jsx)(a.h2,{id:"from-data-to-knowledge-the-power-of-vector-databases",children:"From Data to Knowledge: The Power of Vector Databases"}),"\n",(0,i.jsx)(a.p,{children:(0,i.jsx)(a.strong,{children:"In a world flooded with unstructured data, how can we store not just information, but knowledge itself?"})}),"\n",(0,i.jsxs)(a.p,{children:["This article explores the rise of ",(0,i.jsx)(a.strong,{children:"vector databases"})," \u2014 a revolutionary technology that enables similarity-based search and semantic understanding. We'll break down what vectors are, how they're used in ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/Natural_language_processing",children:"Natural Language Processing (NLP)"})," and how ",(0,i.jsx)(a.strong,{children:"embeddings"})," allow for efficient, contextualized representations of information. Finally, we\u2019ll explore real-world applications and why vector databases are becoming essential in modern AI systems."]}),"\n",(0,i.jsx)(a.h3,{id:"the-rise-of-unstructured-data",children:"The Rise of Unstructured Data"}),"\n",(0,i.jsxs)(a.p,{children:["With the advance of ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/Big_Data",children:"Big Data"}),", billions of connected devices generate real-time information in the form of text, images, videos, and more. These unstructured formats don't fit well into traditional SQL tables and demand more sophisticated storage solutions. This is where ",(0,i.jsx)(a.strong,{children:"vector databases"})," emerge as a game-changing approach, enabling similarity-based searches and unlocking knowledge from complex data."]}),"\n",(0,i.jsx)(a.p,{children:"Before we dive into how vector databases work, let\u2019s first recapitulate the fundamentals of databases."}),"\n",(0,i.jsx)(a.h2,{id:"what-is-a-database",children:"What Is a Database?"}),"\n",(0,i.jsxs)(a.p,{children:["A ",(0,i.jsx)(a.strong,{children:"database"})," is, simply put, an organized collection of information that can be efficiently accessed, managed and updated. It acts as a structure that stores and organizes data, making it easy to query and manipulate using specialized software."]}),"\n",(0,i.jsx)(a.h3,{id:"relational-databases",children:"Relational Databases"}),"\n",(0,i.jsxs)(a.p,{children:[(0,i.jsx)(a.strong,{children:"Relational databases"})," are the most commonly used type. They store data in tables organized into rows and columns \u2014 where each row represents a record and each column represents a field or attribute. This model is ideal for structured data such as customer records, bank transactions, or product inventories."]}),"\n",(0,i.jsxs)(a.p,{children:["A classic example is a customer database with columns for name, address, phone number and email. Relational databases enable fast and precise queries like \u201cfind all customers who made a purchase in the last 30 days,\u201d using a language known as ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/SQL",children:"SQL (Structured Query Language)"}),"."]}),"\n",(0,i.jsx)(a.h3,{id:"non-relational-databases-nosql",children:"Non-Relational Databases (NoSQL)"}),"\n",(0,i.jsxs)(a.p,{children:["Unlike relational databases, ",(0,i.jsx)(a.strong,{children:"NoSQL databases"})," are designed to handle unstructured or semi-structured data, offering more flexibility and scalability. They store information in diverse formats such as JSON documents, key-value pairs or ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/Graph",children:"graphs"}),". This makes them better suited for modern applications like social-media platforms or streaming services."]}),"\n",(0,i.jsx)(a.p,{children:"For instance, a document-oriented NoSQL database might store data in JSON format, allowing for more complex and nested data structures \u2014 without requiring a rigid schema."}),"\n",(0,i.jsxs)(a.p,{children:["Among the categories of non-relational databases, ",(0,i.jsx)(a.strong,{children:"vector databases"})," stand out for their ability to store contextualized data \u2014 also known as ",(0,i.jsx)(a.strong,{children:"knowledge"}),"."]}),"\n",(0,i.jsx)(a.h3,{id:"vector-databases",children:"Vector Databases"}),"\n",(0,i.jsxs)(a.p,{children:[(0,i.jsx)(a.strong,{children:"Vector databases"})," introduce a transformative approach tailored to store and retrieve data as ",(0,i.jsx)(a.strong,{children:"vectors"})," \u2014 mathematical structures that represent information in multiple dimensions. Unlike traditional databases that rely on exact matching, vector databases enable ",(0,i.jsx)(a.strong,{children:"similarity searches"}),", which are ideal for retrieving content like texts, images or sounds based on their characteristics."]}),"\n",(0,i.jsxs)(a.p,{children:["This brings us to a key question: ",(0,i.jsx)(a.em,{children:"what is a vector?"})]}),"\n",(0,i.jsx)(a.h2,{id:"what-is-a-vector",children:"What Is a Vector?"}),"\n",(0,i.jsxs)(a.p,{children:["A ",(0,i.jsx)(a.strong,{children:"vector"})," is a structure that stores information across multiple dimensions. In the case of a three-dimensional vector, it has three coordinates \u2014 ",(0,i.jsx)(a.em,{children:"(x, y, z)"})," \u2014 that define its position or direction in a 3-D space."]}),"\n",(0,i.jsxs)(a.p,{children:["A real-world example is how colors are represented in the ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/RGB",children:(0,i.jsx)(a.strong,{children:"RGB"})})," model (Red, Green, Blue). A color is described by three values, each representing the intensity of red, green and blue. For instance, white is ",(0,i.jsx)(a.code,{children:"[255, 255, 255]"}),", while black is ",(0,i.jsx)(a.code,{children:"[0, 0, 0]"}),"."]}),"\n",(0,i.jsx)(r.A,{img:c(),alt:"RGB cube showing color vectors"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsxs)(a.p,{children:["This concept extends to ",(0,i.jsx)(a.strong,{children:"4-D vectors"}),", such as ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/RGBA",children:(0,i.jsx)(a.strong,{children:"RGBA"})}),", where the fourth component \u201cA\u201d stands for ",(0,i.jsx)(a.strong,{children:"alpha"})," (transpar\xeancia). A semi-transparent red poderia ser ",(0,i.jsx)(a.code,{children:"[255, 0, 0, 0.5]"}),"."]}),"\n",(0,i.jsx)(r.A,{img:g(),alt:"RGBA vector illustration with alpha channel"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsxs)(a.p,{children:["Just as colors can be represented by vectors in three or four dimensions, vector databases use vectors to organize items such as words, images and sounds in multidimensional spaces, where the ",(0,i.jsx)(a.strong,{children:"distance"})," between vectors indicates similarity."]}),"\n",(0,i.jsx)(a.h3,{id:"representing-words-with-vectors",children:"Representing Words with Vectors"}),"\n",(0,i.jsxs)(a.p,{children:["Vectors are widely used to represent more abstract information, such as words. In NLP, converting words into numbers is essential for machines to understand and manipulate them. One of the simplest techniques is ",(0,i.jsx)(a.strong,{children:"One-Hot Encoding"}),"."]}),"\n",(0,i.jsx)(a.h3,{id:"one-hot-encoding",children:"One-Hot Encoding"}),"\n",(0,i.jsx)(a.p,{children:'One-Hot Encoding is a technique in which each word is transformed into a vector of zeros and ones. In this vector, each position corresponds to a specific word in the vocabulary, and only one position holds the value "1" \u2014 all the others are set to "0".'}),"\n",(0,i.jsx)(a.p,{children:"Let\u2019s consider a set of four words: dog, cat, bird, and fish. Using One-Hot Encoding, these words would be represented as follows:"}),"\n",(0,i.jsxs)(a.ul,{children:["\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"dog:"})," [1, 0, 0, 0]"]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"cat:"})," [0, 1, 0, 0]"]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"bird:"})," [0, 0, 1, 0]"]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"fish:"})," [0, 0, 0, 1]"]}),"\n"]}),"\n",(0,i.jsx)(r.A,{img:m(),alt:"One-Hot matrix for four words"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(a.p,{children:'Each vector contains only one "1", indicating the corresponding word, while the "0s" indicate that the other words are not present. Although this approach is simple and easy to implement, it comes with some limitations \u2014 especially as the vocabulary begins to grow.'}),"\n",(0,i.jsx)(a.h3,{id:"the-limitations-of-one-hot-encoding",children:"The Limitations of One-Hot Encoding"}),"\n",(0,i.jsx)(a.p,{children:'Although simple, One-Hot Encoding doesn\'t capture semantic relationships between words. In the example above, "dog" and "cat" are treated as completely different, even though both are household pets, have four legs, two ears, and a tail. Another drawback appears in scenarios with large vocabularies \u2014 say, 10,000 words. In such cases, each word would be represented by a very long vector with a single "1" among 10,000 positions, offering no indication of how the words relate to one another. This inefficiency and lack of semantic information highlight the need for more advanced techniques to represent words as vectors in a meaningful way.'}),"\n",(0,i.jsx)(a.h3,{id:"advanced-representations-embeddings",children:"Advanced Representations: Embeddings"}),"\n",(0,i.jsx)(a.p,{children:"To overcome these limitations, embeddings were introduced \u2014 dense and continuous vector representations of words, where words with similar meanings are placed close to each other in the vector space. Unlike One-Hot Encoding, embeddings capture the meaning of words, positioning related terms \u2014 like \u201cdog\u201d and \u201ccat\u201d \u2014 near each other in the vector space, since they share common features."}),"\n",(0,i.jsx)(r.A,{img:w(),alt:"2-D projection of word clusters"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(a.h2,{id:"what-are-embeddings",children:"What Are Embeddings?"}),"\n",(0,i.jsx)(a.p,{children:"Embeddings are a way to represent data as vectors, where similar items are positioned close to one another in a multidimensional space. They are widely used in areas like NLP to capture relationships between words, images, or sounds more effectively than simpler methods like One-Hot Encoding."}),"\n",(0,i.jsx)(a.p,{children:"These embeddings allow data with similar characteristics to cluster together, which makes similarity search and grouping of related information much more efficient."}),"\n",(0,i.jsx)(a.h3,{id:"a-simple-analogy-colors-in-a-3-d-vector-space",children:"A Simple Analogy: Colors in a 3-D Vector Space"}),"\n",(0,i.jsxs)(a.p,{children:["To make this easier to understand, let\u2019s consider a familiar example: colors in the ",(0,i.jsx)(a.strong,{children:"RGBA"})," model. Each color is represented by four values \u2014 the intensities of red, green, and blue, plus an alpha channel that controls transparency \u2014 placing it in a ",(0,i.jsx)(a.strong,{children:"four-dimensional (4D)"})," space."]}),"\n",(0,i.jsxs)(a.blockquote,{children:["\n",(0,i.jsx)(a.p,{children:"Since we can\u2019t visualize four dimensions directly, we simplify by plotting just the RGB components in a 3D space. The alpha value still exists, but isn't represented visually in this view."}),"\n"]}),"\n",(0,i.jsx)(a.p,{children:"For example:"}),"\n",(0,i.jsxs)(a.ul,{children:["\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"Red:"})," ",(0,i.jsx)(a.code,{children:"[255, 0, 0, 1]"})]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"Light Red:"})," ",(0,i.jsx)(a.code,{children:"[255, 0, 0, 0.5]"})]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"Green:"})," ",(0,i.jsx)(a.code,{children:"[0, 255, 0, 1]"})]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"Blue:"})," ",(0,i.jsx)(a.code,{children:"[0, 0, 255, 1]"})]}),"\n"]}),"\n",(0,i.jsx)(r.A,{img:b(),alt:"3-D plot of Red, Light-Red, Green and Blue"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsxs)(a.p,{children:["When we plot these colors in a 3D space using only the RGB components, we can clearly see that ",(0,i.jsx)(a.strong,{children:"Red"})," and ",(0,i.jsx)(a.strong,{children:"Light Red"})," appear close to each other, while ",(0,i.jsx)(a.strong,{children:"Green"})," and ",(0,i.jsx)(a.strong,{children:"Blue"})," are located farther away. This spatial proximity reflects how similar the colors are \u2014 in this case, due to their shared red intensity."]}),"\n",(0,i.jsx)(a.h3,{id:"representing-words-with-embeddings",children:"Representing Words with Embeddings"}),"\n",(0,i.jsxs)(a.p,{children:["Now, let\u2019s apply this idea to how we represent words. Instead of using three or four dimensions like in the RGB color model, words are typically represented in ",(0,i.jsx)(a.strong,{children:"vector spaces with hundreds or even thousands of dimensions"}),". Each dimension captures some aspect or feature of the word \u2014 such as its meaning, context, or relationships with other words."]}),"\n",(0,i.jsx)(a.p,{children:"For example:"}),"\n",(0,i.jsx)(r.A,{img:f(),alt:"Toy 3-D projection of dog, cat, car and forest"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsxs)(a.p,{children:["In the example above, ",(0,i.jsx)(a.strong,{children:'"dog"'})," and ",(0,i.jsx)(a.strong,{children:'"cat"'})," appear close to each other in the vector space, because both are pets and share contextual similarities. On the other hand, ",(0,i.jsx)(a.strong,{children:'"car"'})," and ",(0,i.jsx)(a.strong,{children:'"forest"'})," are positioned farther away due to their very different meanings and usage patterns."]}),"\n",(0,i.jsxs)(a.blockquote,{children:["\n",(0,i.jsx)(a.p,{children:"Illustrative only \u2014 no actual model was used to generate this plot."}),"\n"]}),"\n",(0,i.jsxs)(a.p,{children:["These ",(0,i.jsx)(a.strong,{children:"high-dimensional vector spaces"})," are generated by ",(0,i.jsx)(a.strong,{children:"embedding models"}),", which analyze large volumes of text and learn to position words based on the contexts in which they appear. The closer two words are in the space, the more semantically similar they are likely to be."]}),"\n",(0,i.jsxs)(a.p,{children:["This representation makes it possible for machines to reason about meaning \u2014 not just recognize exact matches, but ",(0,i.jsx)(a.strong,{children:"understand relatedness"}),". That\u2019s a key foundation for modern AI tasks like question answering, translation, and semantic search."]}),"\n",(0,i.jsx)(a.h3,{id:"explore-a-real-embedding-representation",children:"Explore a Real Embedding Representation"}),"\n",(0,i.jsxs)(a.p,{children:["If you\u2019d like to see what embeddings look like in practice, you can explore a live, interactive visualization using the ",(0,i.jsx)(a.a,{href:"https://projector.tensorflow.org/",children:"TensorFlow Embedding Projector"}),". This tool allows you to ",(0,i.jsx)(a.strong,{children:"navigate through high-dimensional vector spaces"})," and observe how words, images, or other data points are organized based on their semantic relationships."]}),"\n",(0,i.jsxs)(a.p,{children:["You'll see something similar to the example below, where each word is plotted in a space with up to 200 dimensions, reduced visually to 2D or 3D using dimensionality reduction techniques like ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/Principal_component_analysis",children:"PCA"})," ou ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding",children:"t-SNE"}),"."]}),"\n",(0,i.jsx)(r.A,{img:v(),alt:"TensorFlow Embedding Projector showing words near 'store'"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsxs)(a.p,{children:["In this visualization, each dot represents a word, and the proximity between them reflects how similar their meanings are according to the embedding model. For example, the word ",(0,i.jsx)(a.strong,{children:"\u201cstore\u201d"})," is surrounded by words like ",(0,i.jsx)(a.strong,{children:"\u201cshop,\u201d \u201cmarket,\u201d"})," and ",(0,i.jsx)(a.strong,{children:"\u201cretail\u201d"}),", indicating that the model has learned their contextual similarity from large-scale text data."]}),"\n",(0,i.jsxs)(a.blockquote,{children:["\n",(0,i.jsx)(a.p,{children:"This type of embedding space enables machines not only to recognize individual terms, but also to understand relationships between them \u2014 a powerful capability for tasks like semantic search, where the goal is to find relevant information based on meaning rather than exact matches."}),"\n"]}),"\n",(0,i.jsx)(a.h2,{id:"how-vector-db-works",children:"How Does a Vector Database Work?"}),"\n",(0,i.jsxs)(a.p,{children:["Now that we\u2019ve covered the basic concepts, we can better understand how ",(0,i.jsx)(a.strong,{children:"vector databases"})," operate. A vector database organizes data in the form of vectors, which occupy positions in ",(0,i.jsx)(a.strong,{children:"multidimensional space"}),". The main goal is to enable ",(0,i.jsx)(a.strong,{children:"semantic search"})," \u2014 that is, finding similar items based on their ",(0,i.jsx)(a.strong,{children:"vector proximity"}),", rather than exact matches like in traditional databases."]}),"\n",(0,i.jsxs)(a.p,{children:["For example, imagine a database of images where each image is represented as a vector that captures its visual characteristics \u2014 such as color, shape, and texture. If you want to find images similar to a specific picture of a cat, the vector database will compute the ",(0,i.jsx)(a.strong,{children:"distance"})," between the query image's vector and the vectors of other stored images. Those with the ",(0,i.jsx)(a.strong,{children:"shortest distance"})," will be returned as results, since they share similar characteristics."]}),"\n",(0,i.jsxs)(a.p,{children:["A common real-world application of this is ",(0,i.jsx)(a.strong,{children:"facial recognition"}),", where the similarity between the vector of a captured face and that of a registered face can indicate a potential match."]}),"\n",(0,i.jsx)(a.p,{children:"But how exactly is similarity between vectors measured?"}),"\n",(0,i.jsx)(a.h3,{id:"vector-distance-and-similarity-search",children:"Vector Distance and Similarity Search"}),"\n",(0,i.jsxs)(a.p,{children:["In a vector database, items with similar features are clustered close to each other in a ",(0,i.jsx)(a.strong,{children:"multidimensional space"}),'. The "closeness" \u2014 or ',(0,i.jsx)(a.strong,{children:"similarity"})," \u2014 between items is determined by specific ",(0,i.jsx)(a.strong,{children:"distance metrics"}),", such as ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/Euclidean_distance",children:(0,i.jsx)(a.strong,{children:"Euclidean distance"})})," or ",(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/Cosine_similarity",children:(0,i.jsx)(a.strong,{children:"cosine similarity"})}),"."]}),"\n",(0,i.jsxs)(a.p,{children:["In the case of word searches, like in our earlier embeddings example, a vector database can return words that are semantically close to the query. For instance, if you search for the word ",(0,i.jsx)(a.strong,{children:'"feline"'}),", the database might return ",(0,i.jsx)(a.strong,{children:'"cat," "tiger,"'})," or ",(0,i.jsx)(a.strong,{children:'"leopard"'}),", based on how near their vectors are in the semantic space."]}),"\n",(0,i.jsxs)(a.blockquote,{children:["\n",(0,i.jsxs)(a.p,{children:["This kind of vector-based matching allows systems to go beyond surface-level keywords and find results that are ",(0,i.jsx)(a.strong,{children:"meaningfully related"}),", even when the exact words don\u2019t match \u2014 a major advantage in modern AI applications."]}),"\n"]}),"\n",(0,i.jsx)(a.h2,{id:"applications-of-vector-databases",children:"Applications of Vector Databases"}),"\n",(0,i.jsxs)(a.p,{children:["Vector databases are already being widely used to solve challenges related to ",(0,i.jsx)(a.strong,{children:"unstructured data"})," across various domains. Here are some practical examples:"]}),"\n",(0,i.jsxs)(a.ul,{children:["\n",(0,i.jsxs)(a.li,{children:["\n",(0,i.jsxs)(a.p,{children:[(0,i.jsx)(a.strong,{children:"Image Search"}),": Medical systems and platforms like Google Images use vector databases to find visually similar images based on features like color, shape, and texture \u2014 which helps with diagnoses and content discovery."]}),"\n"]}),"\n",(0,i.jsxs)(a.li,{children:["\n",(0,i.jsxs)(a.p,{children:[(0,i.jsx)(a.strong,{children:"Product Recommendations"}),": In e-commerce, vector databases suggest products based on past searches or user purchase history, enabling a more personalized shopping experience."]}),"\n"]}),"\n",(0,i.jsxs)(a.li,{children:["\n",(0,i.jsxs)(a.p,{children:[(0,i.jsx)(a.strong,{children:"Facial Recognition"}),": Security systems use vector databases to compare facial images, identifying matches with high precision \u2014 making authentication and surveillance more effective."]}),"\n"]}),"\n",(0,i.jsxs)(a.li,{children:["\n",(0,i.jsxs)(a.p,{children:[(0,i.jsx)(a.a,{href:"https://en.wikipedia.org/wiki/Retrieval-Augmented_Generation",children:(0,i.jsx)(a.strong,{children:"RAG (Retrieval-Augmented Generation)"})}),": This technique combines document retrieval from vector databases with the response generation capabilities of large language models (LLMs). It allows these models to specialize in specific topics without requiring retraining."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(a.blockquote,{children:["\n",(0,i.jsx)(a.p,{children:(0,i.jsxs)(a.em,{children:["In my ",(0,i.jsx)(a.a,{href:"https://www.linkedin.com/posts/tchez_jornadadeiniciaaexaetocientaedfica-praeamiojovempesquisador-activity-7263597654570369024-2PqS?utm_source=share&utm_medium=member_desktop&rcm=ACoAADUhp3MBjeUrhJg0P5LSvpRa8yf14r7iP3Y",children:"undergraduate thesis"}),", I used RAG to build a chatbot focused on mental health. The system retrieves relevant information and provides more accurate and contextualized responses."]})}),"\n"]}),"\n",(0,i.jsx)(a.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsxs)(a.p,{children:["As unstructured data continues to grow exponentially, ",(0,i.jsx)(a.strong,{children:"vector databases are becoming essential for retrieving information efficiently and meaningfully"}),". By enabling ",(0,i.jsx)(a.strong,{children:"similarity-based search"})," rather than relying on exact matches, they open up new possibilities for interacting with complex data in more intuitive and intelligent ways."]}),"\n",(0,i.jsxs)(a.p,{children:["From applications like ",(0,i.jsx)(a.strong,{children:"image search"}),", ",(0,i.jsx)(a.strong,{children:"product recommendations"}),", and ",(0,i.jsx)(a.strong,{children:"facial recognition"}),", to powering advanced techniques such as ",(0,i.jsx)(a.strong,{children:"RAG"}),", vector databases are poised to play a foundational role in the future of artificial intelligence. They help bridge the gap between raw data and actionable knowledge \u2014 fueling innovation across industries."]}),"\n",(0,i.jsxs)(a.p,{children:["In a world where context and meaning matter more than ever, vector databases offer a paradigm shift. By interpreting data ",(0,i.jsx)(a.strong,{children:"semantically"}),", they have the potential to ",(0,i.jsx)(a.strong,{children:"revolutionize the way we store, retrieve, and understand information"})," \u2014 connecting today\u2019s digital systems with the knowledge-driven technologies of tomorrow."]}),"\n",(0,i.jsx)(a.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(s,{children:[(0,i.jsx)("summary",{children:(0,i.jsx)("strong",{children:"Links"})}),(0,i.jsxs)(a.ul,{children:["\n",(0,i.jsx)(a.li,{children:(0,i.jsx)(a.a,{href:"https://www.oracle.com/br/big-data/what-is-big-data",children:"What is Big Data? \u2013 Oracle"})}),"\n",(0,i.jsx)(a.li,{children:(0,i.jsx)(a.a,{href:"https://www.oracle.com/br/database/what-is-database",children:"What is a Database? \u2013 Oracle"})}),"\n",(0,i.jsx)(a.li,{children:(0,i.jsx)(a.a,{href:"https://aws.amazon.com/pt/what-is/database",children:"What is a Database? \u2013 AWS"})}),"\n",(0,i.jsx)(a.li,{children:(0,i.jsx)(a.a,{href:"https://aws.amazon.com/pt/what-is/vector-databases",children:"What is a Vector Database? \u2013 AWS"})}),"\n",(0,i.jsx)(a.li,{children:(0,i.jsx)(a.a,{href:"https://www.elastic.co/pt/what-is/vector-embedding",children:"What is a Vector Embedding? \u2013 Elastic"})}),"\n",(0,i.jsx)(a.li,{children:(0,i.jsx)(a.a,{href:"https://medium.com/turing-talks/word-embedding-fazendo-o-computador-entender-o-significado-das-palavras-92fe22745057",children:"Word Embedding: Making Computers Understand Word Meaning \u2013 Turing Talks"})}),"\n",(0,i.jsx)(a.li,{children:(0,i.jsx)(a.a,{href:"https://developers.google.com/machine-learning/crash-course/embeddings?hl=pt-br",children:"Embeddings \u2013 Google Machine Learning Crash Course"})}),"\n",(0,i.jsx)(a.li,{children:(0,i.jsx)(a.a,{href:"https://aws.amazon.com/pt/what-is/retrieval-augmented-generation",children:"What is Retrieval-Augmented Generation (RAG)? \u2013 AWS"})}),"\n"]})]})]})}function I(e={}){const{wrapper:a}={...(0,n.R)(),...e.components};return a?(0,i.jsx)(a,{...e,children:(0,i.jsx)(E,{...e})}):E(e)}},9349:(e,a,s)=>{e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:s.p+"assets/ideal-img/image-5.a8a5980.640.png 640w,"+s.p+"assets/ideal-img/image-5.79d1e13.920.png 920w,"+s.p+"assets/ideal-img/image-5.6cc8b79.1166.png 1166w",images:[{path:s.p+"assets/ideal-img/image-5.a8a5980.640.png",width:640,height:299},{path:s.p+"assets/ideal-img/image-5.79d1e13.920.png",width:920,height:429},{path:s.p+"assets/ideal-img/image-5.6cc8b79.1166.png",width:1166,height:544}],src:s.p+"assets/ideal-img/image-5.a8a5980.640.png",placeholder:void 0,width:640,height:299}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAIAAADzBuo/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAATUlEQVR4nF2NSQ7AIAwD+f9rEQdqSBxXgVZdfLHkGclFkiIkzdZ6rU7GSu5S2ZUOQGCgAzCzP05DweB7+eD9M53ul5R4GPsBs3kbz/cJ4fiUbrbbERoAAAAASUVORK5CYII="}},9713:(e,a,s)=>{e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:s.p+"assets/ideal-img/image-1.5ea0378.640.png 640w,"+s.p+"assets/ideal-img/image-1.cff2c0a.920.png 920w,"+s.p+"assets/ideal-img/image-1.40e3993.1166.png 1166w",images:[{path:s.p+"assets/ideal-img/image-1.5ea0378.640.png",width:640,height:138},{path:s.p+"assets/ideal-img/image-1.cff2c0a.920.png",width:920,height:198},{path:s.p+"assets/ideal-img/image-1.40e3993.1166.png",width:1166,height:251}],src:s.p+"assets/ideal-img/image-1.5ea0378.640.png",placeholder:void 0,width:640,height:138}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAACCAIAAADuA9qHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAASUlEQVR4nAE+AMH/AOKIiOKgn+a5uPLJzMm/rKXNzMrV5a+sqaOkpba2twDooaHr29ru///1v8S4o4R0t7a+z+v89/Ls7+/z9PV5NC7scU7kSwAAAABJRU5ErkJggg=="}}}]);